{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NoteBook To Check Point or Polygon Inside Polygon\n",
    "\n",
    "The objective of this notebook is to search a set of points or polygons for spatial overlap with a largerset\n",
    "\n",
    "By Cascsde Tuholske 2019-01-17\n",
    "\n",
    "#### Notes\n",
    "1. Points should be dialated to circles to prevent one falling just outside the larger polygon set (see Lusaka)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depedencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import mapping\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import shape\n",
    "import ast\n",
    "from shapely.geometry import mapping\n",
    "import rasterio\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_points (file):\n",
    "    \"\"\" This function loads a csv \n",
    "    of points and turns it into shapely points\"\"\"\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # creating a geometry column \n",
    "    geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]\n",
    "\n",
    "    # Coordinate reference system : WGS84\n",
    "    crs = {'init': 'epsg:4326'}\n",
    "\n",
    "    # Creating a Geographic data frame \n",
    "    point_gdf = gpd.GeoDataFrame(df, crs=crs, geometry=geometry)\n",
    "    \n",
    "    return point_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_buffer(gpd_df, raduis):\n",
    "    \"Function to make a shapely polygon buffer around a point\"\n",
    "   \n",
    "    # AGU 2018-12-04 - radius set to ~250m at the equator \n",
    "    #radius = 250*1/(111*1000)\n",
    "\n",
    "    # new_gpd_df = gpd.GeoDataFrame()\n",
    "    gpd_df.rename(columns={'geometry':'old_geom'}, inplace=True)\n",
    "    \n",
    "    arr = []\n",
    "    \n",
    "    for point in gpd_df['old_geom']:\n",
    "        buffer = point.buffer(radius)\n",
    "        arr.append((buffer))\n",
    "    \n",
    "    gpd_df['geometry'] = arr\n",
    "    \n",
    "    return gpd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_point (poly, point):\n",
    "    \"\"\"\n",
    "    This function will check if points are inside polygons if given two gpd dataframes with points and polygons\n",
    "    Returns point ids, point geometry, polygon index # and polygon geometry\n",
    "    \"\"\"\n",
    "    \n",
    "    out_arr = [] #return an array <<< ---------------- ASK RYAN IF BETTER DO USE DICT \n",
    "    \n",
    "    for index_point, row_point in point.iterrows():\n",
    "        for index_poly, row_poly in poly.iterrows():\n",
    "            if row_point['geometry'].within(row_poly['geometry']):\n",
    "                point_id = row_point['id']\n",
    "                point_geom = mapping(row_point['geometry']) # makes a dict w/ keys : type and cood\n",
    "                poly_id = index_poly\n",
    "                poly_geom = mapping(row_poly['geometry']) # makes a dict w/ keys : type and cood\n",
    "                \n",
    "                out_arr.append((point_id, \n",
    "                                point_geom, \n",
    "                                poly_id, \n",
    "                                poly_geom))\n",
    "\n",
    "    return out_arr\n",
    "\n",
    "# Note 2018-11-30 update arr to gpd_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_overlap (point_buffer, poly_raster):\n",
    "    \"\"\"\n",
    "    This function will check if point buffers intersect with polygons \n",
    "    if given two gpd dataframes with point buffers and polygons\n",
    "    Returns point ids, point geometry, polygon index #, and polygon geometry in a geopandas DF.\n",
    "    It goes faster if smaller list goes first\n",
    "    \n",
    "    Change TOWN & CITY ARRA\n",
    "    \"\"\"\n",
    "    \n",
    "    # make arrays to fill\n",
    "    country_arr = []\n",
    "    city_arr = []\n",
    "    osm_type_arr = []\n",
    "    lat_arr = []\n",
    "    lon_arr = []\n",
    "    osm_id_arr = [] \n",
    "    FID_arr = [] \n",
    "    poly_geom_arr = []\n",
    "    #point_geom_arr = []\n",
    "    \n",
    "    for index_point_buffer, row_point_buffer in point_buffer.iterrows():\n",
    "        for index_poly_raster, row_poly_raster in poly_raster.iterrows():\n",
    "            if row_point_buffer['geometry'].intersects(row_poly_raster['geometry']):\n",
    "                country = row_point_buffer['country']\n",
    "                city = row_point_buffer['town'] # Need to change town vs city\n",
    "                osm_type = row_point_buffer['osm_type']\n",
    "                lat = row_point_buffer['lat']\n",
    "                lon = row_point_buffer['lon']\n",
    "                osm_id = row_point_buffer['osm_id']\n",
    "                poly_id = row_poly_raster['FID']\n",
    "                poly_geom = shape(mapping(row_poly_raster['geometry'])) # make polygon\n",
    "                #point_geom = row_point_buffer['old_geom']\n",
    "\n",
    "                country_arr.append((country))\n",
    "                city_arr.append((city))\n",
    "                osm_type_arr.append((osm_type))\n",
    "                lat_arr.append((lat))\n",
    "                lon_arr.append((lon))\n",
    "                osm_id_arr.append((osm_id))\n",
    "                FID_arr.append((poly_id))\n",
    "                poly_geom_arr.append((poly_geom))\n",
    "                #point_geom_arr.append((point_geom))\n",
    "    \n",
    "    # put results into a geopandas df\n",
    "    new_gpd_df = gpd.GeoDataFrame()\n",
    "    new_gpd_df['osm_id'] = osm_id_arr\n",
    "    new_gpd_df['FID'] = FID_arr\n",
    "    new_gpd_df['geometry'] = poly_geom_arr\n",
    "    new_gpd_df['country'] = country_arr           \n",
    "    new_gpd_df['city'] = city_arr\n",
    "    new_gpd_df['osm_type'] = osm_type_arr\n",
    "    new_gpd_df['lat'] = lat_arr\n",
    "    new_gpd_df['lon'] = lon_arr\n",
    "    #new_gpd_df['point_geom'] = point_geom_arr\n",
    "    \n",
    "    \n",
    "    return new_gpd_df\n",
    "\n",
    "# Note 2018-11-30 update arr to gpd_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSM Merge Cities and Towns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = '/Users/cascade/Github/Pop-ERL/temp_data/ERL19/'\n",
    "towns = '20190430_osm_DRC_towns.csv'\n",
    "cities = '20190430_osm_DRC_cities.csv'\n",
    "erl_v2_data = '/Users/cascade/Github/Pop-ERL/temp_data/ERL19/ERLv2/'\n",
    "\n",
    "towns_gdf = load_points(erl_v2_data+towns)\n",
    "cities_gdf = load_points(erl_v2_data+cities)\n",
    "\n",
    "towns_gdf['osm_type'] = 'town'\n",
    "cities_gdf['osm_type'] = 'city'\n",
    "\n",
    "print(len(towns_gdf))\n",
    "print(len(cities_gdf))\n",
    "\n",
    "osm_points = pd.concat([towns_gdf, cities_gdf], ignore_index=True, sort = False)\n",
    "print(len(osm_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "osm_points.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGU 2018-12-04 - radius set to ~250m at the equator \n",
    "\n",
    "radius = 250*1/(111*1000)\n",
    "radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_buffer_gdf = point_buffer(osm_points, radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "osm_buffer_gdf.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_buffer_gdf = osm_buffer_gdf.drop(['old_geom'], axis=1)\n",
    "osm_buffer_gdf.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Polygons\n",
    "\n",
    "polygons = 'GHS_POP_GPW42000_GLOBE_R2015A_54009_1k_v1_0_Clip_1500c300'\n",
    "\n",
    "raster_polygons = gpd.read_file(temp_data+polygons+'.shp')\n",
    "print(len(raster_polygons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raster_polygons.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change CRS if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_polygons.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_buffer_gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For GHS CRS\n",
    "\n",
    "crs = {'ellps': 'WGS84',\n",
    " 'lon_0': 0,\n",
    " 'no_defs': True,\n",
    " 'proj': 'moll',\n",
    " 'units': 'm',\n",
    " 'x_0': 0,\n",
    " 'y_0': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_polygons.crs = crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_polygons_crs = raster_polygons.to_crs(osm_buffer_gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For GHS make FID and reset crs\n",
    "FID = list(range(len(raster_polygons)))\n",
    "raster_polygons['DN'] = FID\n",
    "raster_polygons.columns.values[0] = \"FID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raster_polygons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Start \n",
    "1. Data: 2019-01-18 @ 6:22 pm\n",
    "2. Raster Poly File: GHS_POP_GPW42000_GLOBE_R2015A_54009_1k_v1_0_Clip_1500c300.shp\n",
    "3. OSM Town File: 20190114_osm_africa_towns.csv\n",
    "4. Clip: [25000:35000]\n",
    "5. outfile - GHS_POP_GPW42000_GLOBE_R2015A_54009_1k_v1_0_Clip_1500c300_subB1.shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run poly_overlap\n",
    "\n",
    "import time\n",
    "checkpoint = time.time()\n",
    "\n",
    "poly_overlap_out = poly_overlap(osm_buffer_gdf, raster_polygons)\n",
    "\n",
    "print(\"elapsed time is: {}s\".format(time.time()-checkpoint))\n",
    "print(len(poly_overlap_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(poly_overlap_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poly_overlap_out.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_overlap_out.to_file(erl_v2_data+polygons+'_polyoverlap.shp', driver='ESRI Shapefile')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

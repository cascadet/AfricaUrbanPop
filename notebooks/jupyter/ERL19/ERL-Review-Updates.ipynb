{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERL Reivew Updates\n",
    "\n",
    "This notebook is to make new figures and tables for ERL Reviews.\n",
    "\n",
    "By Cascade Tuholkse\n",
    "\n",
    "4-27-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterstats import zonal_stats\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from functools import reduce\n",
    "import squarify\n",
    "from scipy import stats as ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(series):\n",
    "    \n",
    "    \"Function calculates gini coefficent based on https://zhiyzuo.github.io/Plot-Lorenz/\"\n",
    "    ## series to array\n",
    "    arr = series.values\n",
    "    \n",
    "    ## first sort\n",
    "    sorted_arr = arr.copy(np.array)\n",
    "    sorted_arr.sort()\n",
    "    n = arr.size\n",
    "    coef_ = 2. / n\n",
    "    const_ = (n + 1.) / n\n",
    "    weighted_sum = sum([(i+1)*yi for i, yi in enumerate(sorted_arr)])\n",
    "    return coef_*weighted_sum/(sorted_arr.sum()) - const_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "\n",
    "data_raw = '../../data/raw/'\n",
    "data_temp = '../../temp_data/'\n",
    "data_interim = '../../interim/'\n",
    "data_analysis = '/Users/cascade/Github/Pop-ERL/temp_data/ERL19/ERL_data/Data20190222/'\n",
    "erl_data = '/Users/cascade/Github/Pop-ERL/temp_data/ERL19/ERL_data/'\n",
    "downloads = '/Users/cascade/Downloads/'\n",
    "erl_vs_data = '/Users/cascade/Github/Pop-ERL/temp_data/ERL19/ERLv2/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data\n",
    "This code cleans data to fix national boundary issues among polygons 2019-04-29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urban merge files still have duplicates\n",
    "\n",
    "# GHS is good\n",
    "GHS2000m = gpd.read_file(data_analysis+'GHS_POP_GPW42000_urbanmerge_PopTot.shp', driver = 'ESRI Shapefile')\n",
    "GHS2015m = gpd.read_file(data_analysis+'GHS_POP_GPW42015_urbanmerge_PopTot.shp', driver = 'ESRI Shapefile')\n",
    "\n",
    "\n",
    "## Load Data\n",
    "\n",
    "#WP 2015\n",
    "WP2015_dup = gpd.read_file(data_analysis+'AFR_PPP_2015_adj_v2_final20190122.shp')\n",
    "WP2015_Sudan = gpd.read_file(data_analysis+'AFR_PPP_2015_adj_v2_S_Sudan_1500c300_polyoverlapPopTot.shp')\n",
    "\n",
    "\n",
    "#WPE\n",
    "WPE2016_dup = gpd.read_file(data_analysis+'WPE_1KM_2016_final20190122.shp')\n",
    "WPE2016_Sudan = gpd.read_file(data_analysis+'WPE_1KM_2016_Pop_Clip_S_Sudan_1500c300_polyoverlapPopTot.shp')\n",
    "\n",
    "#LS \n",
    "LS2015_dup = gpd.read_file(data_analysis+'LS15_final20190122.shp')\n",
    "LS2015_Sudan = gpd.read_file(data_analysis+'LS15_w001001_Clip_S_Sudan_1500c300_polyoverlapPopTot.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3854\n",
      "3871\n"
     ]
    }
   ],
   "source": [
    "# Merge in South Sudan ... do each \n",
    "\n",
    "frames1 = [WP2015_dup, WP2015_Sudan]\n",
    "frames2 = [WPE2016_dup, WPE2016_Sudan]\n",
    "frames3 = [LS2015_dup, LS2015_Sudan]\n",
    "\n",
    "\n",
    "print(len(WP2015_dup))\n",
    "WP2015_merge = pd.concat(frames1)\n",
    "print(len(WP2015_dup))\n",
    "WPE2016_merge = pd.concat(frames2)\n",
    "LS2015_merge = pd.concat(frames3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3854\n",
      "3871\n",
      "5598\n",
      "5705\n",
      "5552\n",
      "5659\n"
     ]
    }
   ],
   "source": [
    "print(len(WP2015_dup))\n",
    "print(len(WP2015_merge))\n",
    "\n",
    "print(len(WPE2016_dup))\n",
    "print(len(WPE2016_merge))\n",
    "\n",
    "print(len(LS2015_dup))\n",
    "print(len(LS2015_merge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Files ... these files have FID duplicates and those with <5000 people starting point\n",
    "# for ERL v2 ALL figures and data ... 20190429_all.csv\n",
    "GHS2015m.to_csv(erl_vs_data+'GHS2015_20190429_all.csv')\n",
    "GHS2000m.to_csv(erl_vs_data+'GHS2000_20190429_all.csv')\n",
    "WP2015_merge.to_csv(erl_data+'WP2015_20190429_all.csv')\n",
    "WPE2016_merge.to_csv(erl_vs_data+'WPE2016_20190429_all.csv')\n",
    "LS2015_merge.to_csv(erl_vs_data+'LS2015_20190429_all.csv')\n",
    "\n",
    "GHS2015m.to_file(erl_vs_data+'GHS2015_20190429_all.shp', driver = 'ESRI Shapefile')\n",
    "GHS2000m.to_file(erl_vs_data+'GHS2000_20190429_all.shp', driver = 'ESRI Shapefile')\n",
    "WP2015_merge.to_file(erl_vs_data+'WP2015_20190429_all.shp', driver = 'ESRI Shapefile')\n",
    "WPE2016_merge.to_file(erl_vs_data+'WPE2016_20190429_all.shp', driver = 'ESRI Shapefile')\n",
    "LS2015_merge.to_file(erl_vs_data+'LS2015_20190429_all.shp', driver = 'ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data: ...20190222.shp files have FIDs removed, S Sudan added, rainfall zones, and regions, <5k removed\n",
    "\n",
    "# GHS2000 = gpd.read_file(data_analysis+'GHS_POP_GPW42000_20190222.shp', driver = 'ESRI Shapefile')\n",
    "# GHS2015 = gpd.read_file(data_analysis+'GHS_POP_GPW42015_20190222.shp', driver = 'ESRI Shapefile')\n",
    "# WP2000 = gpd.read_file(data_analysis+'AFR_PPP_2000_adj_v2_20190222.shp', driver = 'ESRI Shapefile')\n",
    "# WP2015 = gpd.read_file(data_analysis+'AFR_PPP_2015_adj_v2_20190222.shp', driver = 'ESRI Shapefile')\n",
    "# LS2015 = gpd.read_file(data_analysis+'WPE_1KM_2016_20190222.shp', driver = 'ESRI Shapefile')\n",
    "# WPE2016 = gpd.read_file(data_analysis+'LS15_20190222.shp', driver = 'ESRI Shapefile')\n",
    "\n",
    "# Load data to fix polygon overlap problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(GHS2000))\n",
    "print(len(GHS2015))\n",
    "print(len(WP2015))\n",
    "print(len(LS2015))\n",
    "print(len(WPE2016))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WP 2015 Chunks\n",
    "WP2015_50k = WP2015.loc[(WP2015['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(WP2015_50k)\n",
    "\n",
    "WP2015_100k = WP2015.loc[(WP2015['PopTot'] > 5*10**4) & (WP2015['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(WP2015_100k)\n",
    "\n",
    "WP2015_300k = WP2015.loc[(WP2015['PopTot'] > 10**5) & (WP2015['PopTot'] <= 3*10**5), 'PopTot'].sum()\n",
    "print(WP2015_300k)\n",
    "\n",
    "WP2015_500k = WP2015.loc[(WP2015['PopTot'] > 3*10**5) & (WP2015['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(WP2015_500k)\n",
    "\n",
    "WP2015_1m = WP2015.loc[(WP2015['PopTot'] > 5*10**5) & (WP2015['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(WP2015_1m)\n",
    "\n",
    "WP2015_5m = WP2015.loc[(WP2015['PopTot'] > 10**6) & (WP2015['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(WP2015_5m)\n",
    "\n",
    "WP2015_5mplus = WP2015.loc[(WP2015['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(WP2015_5mplus)\n",
    "\n",
    "WP2015_chunks = [WP2015_50k, WP2015_100k, WP2015_300k, WP2015_500k, WP2015_1m, WP2015_5m, WP2015_5mplus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LS 2015 Chunks\n",
    "LS2015_50k = LS2015.loc[(LS2015['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(LS2015_50k)\n",
    "\n",
    "LS2015_100k = LS2015.loc[(LS2015['PopTot'] > 5*10**4) & (LS2015['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(LS2015_100k)\n",
    "\n",
    "LS2015_300k = LS2015.loc[(LS2015['PopTot'] > 10**5) & (LS2015['PopTot'] <= 3*10**5), 'PopTot'].sum()\n",
    "print(LS2015_300k)\n",
    "\n",
    "LS2015_500k = LS2015.loc[(LS2015['PopTot'] > 3*10**5) & (LS2015['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(LS2015_500k)\n",
    "\n",
    "LS2015_1m = LS2015.loc[(LS2015['PopTot'] > 5*10**5) & (LS2015['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(LS2015_1m)\n",
    "\n",
    "LS2015_5m = LS2015.loc[(LS2015['PopTot'] > 10**6) & (LS2015['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(LS2015_5m)\n",
    "\n",
    "LS2015_5mplus = LS2015.loc[(LS2015['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(LS2015_5mplus)\n",
    "\n",
    "LS2015_chunks = [LS2015_50k, LS2015_100k, LS2015_300k, LS2015_500k, LS2015_1m, LS2015_5m, LS2015_5mplus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WPE 2016 Chunks\n",
    "WPE2016_50k = WPE2016.loc[(WPE2016['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(WPE2016_50k)\n",
    "\n",
    "WPE2016_100k = WPE2016.loc[(WPE2016['PopTot'] > 5*10**4) & (WPE2016['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(WPE2016_100k)\n",
    "\n",
    "WPE2016_300k = WPE2016.loc[(WPE2016['PopTot'] > 10**5) & (WPE2016['PopTot'] <= 3*10**5), 'PopTot'].sum()\n",
    "print(WPE2016_300k)\n",
    "\n",
    "WPE2016_500k = WPE2016.loc[(WPE2016['PopTot'] > 3*10**5) & (WPE2016['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(WPE2016_500k)\n",
    "\n",
    "WPE2016_1m = WPE2016.loc[(WPE2016['PopTot'] > 5*10**5) & (WPE2016['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(WPE2016_1m)\n",
    "\n",
    "WPE2016_5m = WPE2016.loc[(WPE2016['PopTot'] > 10**6) & (WPE2016['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(WPE2016_5m)\n",
    "\n",
    "WPE2016_5mplus = WPE2016.loc[(WPE2016['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(WPE2016_5mplus)\n",
    "\n",
    "WPE2016_chunks = [WPE2016_50k, WPE2016_100k, WPE2016_300k, WPE2016_500k, WPE2016_1m, WPE2016_5m, WPE2016_5mplus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHS 2015 Chunks\n",
    "GHS2015_50k = GHS2015.loc[(GHS2015['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(GHS2015_50k)\n",
    "\n",
    "GHS2015_100k = GHS2015.loc[(GHS2015['PopTot'] > 5*10**4) & (GHS2015['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(GHS2015_100k)\n",
    "\n",
    "GHS2015_300k = GHS2015.loc[(GHS2015['PopTot'] > 10**5) & (GHS2015['PopTot'] <= 3*10**5), 'PopTot'].sum()\n",
    "print(GHS2015_300k)\n",
    "\n",
    "GHS2015_500k = GHS2015.loc[(GHS2015['PopTot'] > 3*10**5) & (GHS2015['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(GHS2015_500k)\n",
    "\n",
    "GHS2015_1m = GHS2015.loc[(GHS2015['PopTot'] > 5*10**5) & (GHS2015['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(GHS2015_1m)\n",
    "\n",
    "GHS2015_5m = GHS2015.loc[(GHS2015['PopTot'] > 10**6) & (GHS2015['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2015_5m)\n",
    "\n",
    "GHS2015_5mplus = GHS2015.loc[(GHS2015['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2015_5mplus)\n",
    "\n",
    "GHS2015_chunks = [GHS2015_50k, GHS2015_100k, GHS2015_300k, GHS2015_500k, GHS2015_1m, GHS2015_5m, GHS2015_5mplus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GHS 2000 Chunks\n",
    "GHS2000_50k = GHS2000.loc[(GHS2000['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(GHS2000_50k)\n",
    "\n",
    "GHS2000_100k = GHS2000.loc[(GHS2000['PopTot'] > 5*10**4) & (GHS2000['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(GHS2000_100k)\n",
    "\n",
    "GHS2000_300k = GHS2000.loc[(GHS2000['PopTot'] > 10**5) & (GHS2000['PopTot'] <= 3*10**5), 'PopTot'].sum()\n",
    "print(GHS2000_300k)\n",
    "\n",
    "GHS2000_500k = GHS2000.loc[(GHS2000['PopTot'] > 3*10**5) & (GHS2000['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(GHS2000_500k)\n",
    "\n",
    "GHS2000_1m = GHS2000.loc[(GHS2000['PopTot'] > 5*10**5) & (GHS2000['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(GHS2000_1m)\n",
    "\n",
    "GHS2000_5m = GHS2000.loc[(GHS2000['PopTot'] > 10**6) & (GHS2000['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2000_5m)\n",
    "\n",
    "GHS2000_5mplus = GHS2000.loc[(GHS2000['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2000_5mplus)\n",
    "\n",
    "GHS2000_chunks = [GHS2000_50k, GHS2000_100k, GHS2000_300k, GHS2000_500k, GHS2000_1m, GHS2000_5m, GHS2000_5mplus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rain Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk by Rain Zone \n",
    "\n",
    "# GHS 2000\n",
    "GHS2000_arid = GHS2000[GHS2000['rain_zone'] == 'Arid']\n",
    "GHS2000_semi = GHS2000[GHS2000['rain_zone'] == 'Semi-arid']\n",
    "GHS2000_sub = GHS2000[GHS2000['rain_zone'] == 'Sub-humid']\n",
    "GHS2000_humid = GHS2000[GHS2000['rain_zone'] == 'Humid']\n",
    "\n",
    "# GHS 2015\n",
    "GHS2015_arid = GHS2015[GHS2015['rain_zone'] == 'Arid']\n",
    "GHS2015_semi = GHS2015[GHS2015['rain_zone'] == 'Semi-arid']\n",
    "GHS2015_sub = GHS2015[GHS2015['rain_zone'] == 'Sub-humid']\n",
    "GHS2015_humid = GHS2015[GHS2015['rain_zone'] == 'Humid']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GHS 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHS 2000 Arid Chunks \n",
    "GHS2000_arid_50k = GHS2000_arid.loc[(GHS2000_arid['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(GHS2000_arid_50k)\n",
    "\n",
    "GHS2000_arid_100k = GHS2000_arid.loc[(GHS2000_arid['PopTot'] > 5*10**4) & (GHS2000_arid['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(GHS2000_arid_100k)\n",
    "\n",
    "GHS2000_arid_300k = GHS2000_arid.loc[(GHS2000_arid['PopTot'] > 10**5) & (GHS2000_arid['PopTot'] <= 3*10**5), 'PopTot'].sum()\n",
    "print(GHS2000_arid_300k)\n",
    "\n",
    "GHS2000_arid_500k = GHS2000_arid.loc[(GHS2000_arid['PopTot'] > 3*10**5) & (GHS2000_arid['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(GHS2000_arid_500k)\n",
    "\n",
    "GHS2000_arid_1m = GHS2000_arid.loc[(GHS2000_arid['PopTot'] > 5*10**5) & (GHS2000_arid['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(GHS2000_arid_1m)\n",
    "\n",
    "GHS2000_arid_5m = GHS2000_arid.loc[(GHS2000_arid['PopTot'] > 10**6) & (GHS2000_arid['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2000_arid_5m)\n",
    "\n",
    "GHS2000_arid_5mplus = GHS2000_arid.loc[(GHS2000_arid['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2000_arid_5mplus)\n",
    "\n",
    "GHS2000_arid_chunks = [GHS2000_arid_50k, GHS2000_arid_100k, GHS2000_arid_300k, GHS2000_arid_500k,\n",
    "                      GHS2000_arid_1m, GHS2000_arid_5m, GHS2000_arid_5mplus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHS Semi Arid Chunks \n",
    "GHS2000_semi_50k = GHS2000_semi.loc[(GHS2000_semi['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(GHS2000_semi_50k)\n",
    "\n",
    "GHS2000_semi_100k = GHS2000_semi.loc[(GHS2000_semi['PopTot'] > 5*10**4) & (GHS2000_semi['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(GHS2000_semi_100k)\n",
    "\n",
    "GHS2000_semi_300k = GHS2000_semi.loc[(GHS2000_semi['PopTot'] > 10**5) & (GHS2000_semi['PopTot'] <= 3*10**5), 'PopTot'].sum()\n",
    "print(GHS2000_semi_300k)\n",
    "\n",
    "GHS2000_semi_500k = GHS2000_semi.loc[(GHS2000_semi['PopTot'] > 3*10**5) & (GHS2000_semi['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(GHS2000_semi_500k)\n",
    "\n",
    "GHS2000_semi_1m = GHS2000_semi.loc[(GHS2000_semi['PopTot'] > 5*10**5) & (GHS2000_semi['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(GHS2000_semi_1m)\n",
    "\n",
    "GHS2000_semi_5m = GHS2000_semi.loc[(GHS2000_semi['PopTot'] > 10**6) & (GHS2000_semi['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2000_semi_5m)\n",
    "\n",
    "GHS2000_semi_5mplus = GHS2000_semi.loc[(GHS2000_semi['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2000_semi_5mplus)\n",
    "\n",
    "GHS2000_semi_chunks = [GHS2000_semi_50k, GHS2000_semi_100k, GHS2000_semi_300k, GHS2000_semi_500k,\n",
    "                      GHS2000_semi_1m, GHS2000_semi_5m, GHS2000_semi_5mplus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHS Sub Humid Chunks \n",
    "GHS2000_sub_50k = GHS2000_sub.loc[(GHS2000_sub['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(GHS2000_sub_50k)\n",
    "\n",
    "GHS2000_sub_100k = GHS2000_sub.loc[(GHS2000_sub['PopTot'] > 5*10**4) & (GHS2000_sub['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(GHS2000_sub_100k)\n",
    "\n",
    "GHS2000_sub_300k = GHS2000_sub.loc[(GHS2000_sub['PopTot'] > 10**5) & (GHS2000_sub['PopTot'] <= 3*10**5), 'PopTot'].sum()\n",
    "print(GHS2000_sub_300k)\n",
    "\n",
    "GHS2000_sub_500k = GHS2000_sub.loc[(GHS2000_sub['PopTot'] > 3*10**5) & (GHS2000_sub['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(GHS2000_sub_500k)\n",
    "\n",
    "GHS2000_sub_1m = GHS2000_sub.loc[(GHS2000_sub['PopTot'] > 5*10**5) & (GHS2000_sub['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(GHS2000_sub_1m)\n",
    "\n",
    "GHS2000_sub_5m = GHS2000_sub.loc[(GHS2000_sub['PopTot'] > 10**6) & (GHS2000_sub['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2000_sub_5m)\n",
    "\n",
    "GHS2000_sub_5mplus = GHS2000_sub.loc[(GHS2000_sub['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2000_sub_5mplus)\n",
    "\n",
    "GHS2000_sub_chunks = [GHS2000_sub_50k, GHS2000_sub_100k, GHS2000_sub_300k, GHS2000_sub_500k,\n",
    "                      GHS2000_sub_1m, GHS2000_sub_5m, GHS2000_sub_5mplus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# GHS Humid Chunks \n",
    "GHS2000_humid_50k = GHS2000_humid.loc[(GHS2000_humid['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(GHS2000_humid_50k)\n",
    "\n",
    "GHS2000_humid_100k = GHS2000_humid.loc[(GHS2000_humid['PopTot'] > 5*10**4) & (GHS2000_humid['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(GHS2000_humid_100k)\n",
    "\n",
    "GHS2000_humid_300k = GHS2000_humid.loc[(GHS2000_humid['PopTot'] > 10**5) & (GHS2000_humid['PopTot'] <= 3*10**5), 'PopTot'].sum()\n",
    "print(GHS2000_humid_300k)\n",
    "\n",
    "GHS2000_humid_500k = GHS2000_humid.loc[(GHS2000_humid['PopTot'] > 3*10**5) & (GHS2000_humid['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(GHS2000_humid_500k)\n",
    "\n",
    "GHS2000_humid_1m = GHS2000_humid.loc[(GHS2000_humid['PopTot'] > 5*10**5) & (GHS2000_humid['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(GHS2000_humid_1m)\n",
    "\n",
    "GHS2000_humid_5m = GHS2000_humid.loc[(GHS2000_humid['PopTot'] > 10**6) & (GHS2000_humid['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2000_humid_5m)\n",
    "\n",
    "GHS2000_humid_5mplus = GHS2000_humid.loc[(GHS2000_humid['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2000_humid_5mplus)\n",
    "\n",
    "GHS2000_humid_chunks = [GHS2000_humid_50k, GHS2000_humid_100k, GHS2000_humid_300k, GHS2000_humid_500k,\n",
    "                      GHS2000_humid_1m, GHS2000_humid_5m, GHS2000_humid_5mplus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GHS 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHS 2015 Arid Chunks \n",
    "GHS2015_arid_50k = GHS2015_arid.loc[(GHS2015_arid['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(GHS2015_arid_50k)\n",
    "\n",
    "GHS2015_arid_100k = GHS2015_arid.loc[(GHS2015_arid['PopTot'] > 5*10**4) & (GHS2015_arid['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(GHS2015_arid_100k)\n",
    "\n",
    "GHS2015_arid_300k = GHS2015_arid.loc[(GHS2015_arid['PopTot'] > 10**5) & (GHS2015_arid['PopTot'] <= 3*10**5), 'PopTot'].sum()\n",
    "print(GHS2015_arid_300k)\n",
    "\n",
    "GHS2015_arid_500k = GHS2015_arid.loc[(GHS2015_arid['PopTot'] > 3*10**5) & (GHS2015_arid['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(GHS2015_arid_500k)\n",
    "\n",
    "GHS2015_arid_1m = GHS2015_arid.loc[(GHS2015_arid['PopTot'] > 5*10**5) & (GHS2015_arid['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(GHS2015_arid_1m)\n",
    "\n",
    "GHS2015_arid_5m = GHS2015_arid.loc[(GHS2015_arid['PopTot'] > 10**6) & (GHS2015_arid['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2015_arid_5m)\n",
    "\n",
    "GHS2015_arid_5mplus = GHS2015_arid.loc[(GHS2015_arid['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2015_arid_5mplus)\n",
    "\n",
    "GHS2015_arid_chunks = [GHS2015_arid_50k, GHS2015_arid_100k, GHS2015_arid_300k, GHS2015_arid_500k,\n",
    "                      GHS2015_arid_1m, GHS2015_arid_5m, GHS2015_arid_5mplus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHS Semi Arid Chunks \n",
    "GHS2015_semi_50k = GHS2015_semi.loc[(GHS2015_semi['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(GHS2015_semi_50k)\n",
    "\n",
    "GHS2015_semi_100k = GHS2015_semi.loc[(GHS2015_semi['PopTot'] > 5*10**4) & (GHS2015_semi['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(GHS2015_semi_100k)\n",
    "\n",
    "GHS2015_semi_300k = GHS2015_semi.loc[(GHS2015_semi['PopTot'] > 10**5) & (GHS2015_semi['PopTot'] <= 3*10**5), 'PopTot'].sum()\n",
    "print(GHS2015_semi_300k)\n",
    "\n",
    "GHS2015_semi_500k = GHS2015_semi.loc[(GHS2015_semi['PopTot'] > 3*10**5) & (GHS2015_semi['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(GHS2015_semi_500k)\n",
    "\n",
    "GHS2015_semi_1m = GHS2015_semi.loc[(GHS2015_semi['PopTot'] > 5*10**5) & (GHS2015_semi['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(GHS2015_semi_1m)\n",
    "\n",
    "GHS2015_semi_5m = GHS2015_semi.loc[(GHS2015_semi['PopTot'] > 10**6) & (GHS2015_semi['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2015_semi_5m)\n",
    "\n",
    "GHS2015_semi_5mplus = GHS2015_semi.loc[(GHS2015_semi['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2015_semi_5mplus)\n",
    "\n",
    "GHS2015_semi_chunks = [GHS2015_semi_50k, GHS2015_semi_100k, GHS2015_semi_300k, GHS2015_semi_500k,\n",
    "                      GHS2015_semi_1m, GHS2015_semi_5m, GHS2015_semi_5mplus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHS Sub Humid Chunks \n",
    "GHS2015_sub_50k = GHS2015_sub.loc[(GHS2015_sub['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(GHS2015_sub_50k)\n",
    "\n",
    "GHS2015_sub_100k = GHS2015_sub.loc[(GHS2015_sub['PopTot'] > 5*10**4) & (GHS2015_sub['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(GHS2015_sub_100k)\n",
    "\n",
    "GHS2015_sub_300k = GHS2015_sub.loc[(GHS2015_sub['PopTot'] > 10**5) & (GHS2015_sub['PopTot'] <= 3*10**5), 'PopTot'].sum()\n",
    "print(GHS2015_sub_300k)\n",
    "\n",
    "GHS2015_sub_500k = GHS2015_sub.loc[(GHS2015_sub['PopTot'] > 3*10**5) & (GHS2015_sub['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(GHS2015_sub_500k)\n",
    "\n",
    "GHS2015_sub_1m = GHS2015_sub.loc[(GHS2015_sub['PopTot'] > 5*10**5) & (GHS2015_sub['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(GHS2015_sub_1m)\n",
    "\n",
    "GHS2015_sub_5m = GHS2015_sub.loc[(GHS2015_sub['PopTot'] > 10**6) & (GHS2015_sub['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2015_sub_5m)\n",
    "\n",
    "GHS2015_sub_5mplus = GHS2015_sub.loc[(GHS2015_sub['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2015_sub_5mplus)\n",
    "\n",
    "GHS2015_sub_chunks = [GHS2015_sub_50k, GHS2015_sub_100k, GHS2015_sub_300k, GHS2015_sub_500k,\n",
    "                      GHS2015_sub_1m, GHS2015_sub_5m, GHS2015_sub_5mplus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHS Humid Chunks \n",
    "GHS2015_humid_50k = GHS2015_humid.loc[(GHS2015_humid['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(GHS2015_humid_50k)\n",
    "\n",
    "GHS2015_humid_100k = GHS2015_humid.loc[(GHS2015_humid['PopTot'] > 5*10**4) & (GHS2015_humid['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(GHS2015_humid_100k)\n",
    "\n",
    "GHS2015_humid_300k = GHS2015_humid.loc[(GHS2015_humid['PopTot'] > 10**5) & (GHS2015_humid['PopTot'] <= 3*10**5), 'PopTot'].sum()\n",
    "print(GHS2015_humid_300k)\n",
    "\n",
    "GHS2015_humid_500k = GHS2015_humid.loc[(GHS2015_humid['PopTot'] > 3*10**5) & (GHS2015_humid['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(GHS2015_humid_500k)\n",
    "\n",
    "GHS2015_humid_1m = GHS2015_humid.loc[(GHS2015_humid['PopTot'] > 5*10**5) & (GHS2015_humid['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(GHS2015_humid_1m)\n",
    "\n",
    "GHS2015_humid_5m = GHS2015_humid.loc[(GHS2015_humid['PopTot'] > 10**6) & (GHS2015_humid['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2015_humid_5m)\n",
    "\n",
    "GHS2015_humid_5mplus = GHS2015_humid.loc[(GHS2015_humid['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2015_humid_5mplus)\n",
    "\n",
    "GHS2015_humid_chunks = [GHS2015_humid_50k, GHS2015_humid_100k, GHS2015_humid_300k, GHS2015_humid_500k,\n",
    "                      GHS2015_humid_1m, GHS2015_humid_5m, GHS2015_humid_5mplus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot by Dataset for 2015\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dictionary = plt.figure()\n",
    "\n",
    "# Tick Lables\n",
    "ticks_bar = ['<50K', '50-100K', '100-300K','300-500K', '500K-1M', '1-5M' , '>5M']\n",
    "\n",
    "# make plot\n",
    "sns.set(font_scale=3)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "# Bar locations\n",
    "a = [0-.4,1-.4,2-.4,3-.4,4-.4,5-.4,6-.4]\n",
    "b = [0-.2,1-.2,2-.2,3-.2,4-.2,5-.2,6-.2]\n",
    "c = [0,1,2,3,4,5,6]\n",
    "d = [0+.2,1+.2,2+.2,3+.2,4+.2,5+.2,6+.2]\n",
    "\n",
    "\n",
    "# Bars\n",
    "plt.bar(a, [x / 10**6 for x in WP2015_chunks], width=0.2, align='center', alpha  = 0.7, color = 'Blue')\n",
    "plt.bar(b, [x / 10**6 for x in LS2015_chunks], width=0.2, align='center', alpha  = 0.7, color = 'Green')\n",
    "plt.bar(c, [x / 10**6 for x in GHS2015_chunks], width=0.2, align='center', alpha  = 0.7, color = 'Orange')\n",
    "plt.bar(d, [x / 10**6 for x in WPE2016_chunks], width=0.2, align='center', alpha = 0.7, color = 'Purple')\n",
    "\n",
    "# Legend \n",
    "bar_leg = ['WorldPop 2015', 'LandScan 2015', 'GHS-Pop 2015', 'WPE 2016']\n",
    "plt.legend(bar_leg,loc=2, facecolor= 'white', edgecolor = 'white')\n",
    "\n",
    "# Ticks\n",
    "plt.xticks(range(len(ticks_bar)), ticks_bar, size = 28)\n",
    "#plt.gca().set_yscale('log')\n",
    "\n",
    "# Size & Color\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(25, 15)\n",
    "ax.set_facecolor('White')\n",
    "\n",
    "# Labels \n",
    "plt.xlabel('Settlement Size', size = 32)\n",
    "plt.ylabel('Population (millions)', size = 32)\n",
    "plt.title('Total Urban Population by Settlement Size for Africa')\n",
    "\n",
    "# Save\n",
    "# fig.savefig('/Users/cascade/Desktop/'+'PopAll_bar.png', dpi=700, transparent=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot by for GHS 2000 & 2015 \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dictionary = plt.figure()\n",
    "\n",
    "# Tick Lables\n",
    "ticks_bar = ['<50K', '50-100K', '100-300K','300-500K', '500K-1M', '1-5M' , '>5M']\n",
    "\n",
    "# make plot\n",
    "sns.set(font_scale=3)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "# Bar locations\n",
    "a = [0-.4,1-.4,2-.4,3-.4,4-.4,5-.4,6-.4]\n",
    "b = [0-.2,1-.2,2-.2,3-.2,4-.2,5-.2,6-.2]\n",
    "c = [0,1,2,3,4,5,6]\n",
    "d = [0+.2,1+.2,2+.2,3+.2,4+.2,5+.2,6+.2]\n",
    "\n",
    "\n",
    "# Bars\n",
    "plt.bar(a, [x / 10**6 for x in GHS2000_chunks], width=0.2, align='center', alpha  = 0.7, color = 'Blue')\n",
    "plt.bar(b, [x / 10**6 for x in GHS2015_chunks], width=0.2, align='center', alpha  = 0.7, color = 'Green')\n",
    "\n",
    "# Legend \n",
    "bar_leg = ['GHS-Pop 2000', 'GHS-Pop 2015']\n",
    "plt.legend(bar_leg,loc=2, facecolor= 'white', edgecolor = 'white')\n",
    "\n",
    "# Ticks\n",
    "plt.xticks(range(len(ticks_bar)), ticks_bar, size = 28)\n",
    "#plt.gca().set_yscale('log')\n",
    "\n",
    "# Size & Color\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(25, 15)\n",
    "ax.set_facecolor('White')\n",
    "\n",
    "# Labels \n",
    "plt.xlabel('Settlement Size', size = 32)\n",
    "plt.ylabel('Population (millions)', size = 32)\n",
    "plt.title('Total Urban Population by Settlement Size for Africa 2000 & 2015')\n",
    "\n",
    "# Save\n",
    "# fig.savefig('/Users/cascade/Desktop/'+'PopAll_bar.png', dpi=700, transparent=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot by for GHS 2000 & 2015 Arid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dictionary = plt.figure()\n",
    "\n",
    "# Tick Lables\n",
    "ticks_bar = ['<50K', '50-100K', '100-300K','300-500K', '500K-1M', '1-5M' , '>5M']\n",
    "\n",
    "# make plot\n",
    "sns.set(font_scale=3)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "# Bar locations\n",
    "c = [0-.4,1-.4,2-.4,3-.4,4-.4,5-.4,6-.4]\n",
    "d = [0-.1,1-.1,2-.1,3-.1,4-.1,5-.1,6-.1]\n",
    "a = [0,1,2,3,4,5,6]\n",
    "b = [0+.1,1+.1,2+.1,3+.1,4+.1,5+.1,6+.1]\n",
    "\n",
    "\n",
    "# Bars\n",
    "plt.bar(d, [x / 10**6 for x in GHS2000_humid_chunks], width=0.2, align='center', alpha  = 0.7, color = 'Blue')\n",
    "plt.bar(b, [x / 10**6 for x in GHS2015_humid_chunks], width=0.2, align='center', alpha  = 0.7, color = 'Green')\n",
    "\n",
    "# Legend \n",
    "bar_leg = ['GHS-Pop 2000', 'GHS-Pop 2015']\n",
    "plt.legend(bar_leg,loc=2, facecolor= 'white', edgecolor = 'white')\n",
    "\n",
    "# Ticks\n",
    "plt.xticks(range(len(ticks_bar)), ticks_bar, size = 28)\n",
    "#plt.gca().set_yscale('log')\n",
    "\n",
    "# Size & Color\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(25, 15)\n",
    "ax.set_facecolor('White')\n",
    "\n",
    "# Labels \n",
    "plt.xlabel('Settlement Size', size = 32)\n",
    "plt.ylabel('Population (millions)', size = 32)\n",
    "plt.title('Total Urban Population by Settlement Size for Africa 2000 & 2015')\n",
    "\n",
    "# Save\n",
    "# fig.savefig('/Users/cascade/Desktop/'+'PopAll_bar.png', dpi=700, transparent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lorenz Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = GHS2015[GHS2015[col] == area]\n",
    "test = GHS2015\n",
    "test = test[test.PopTot>5*10**6]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Data for Lorenz\n",
    "\n",
    "# All Africa\n",
    "\n",
    "#area = 'Africa'\n",
    "# X = np.sort(np.array(GHS2000.PopTot))\n",
    "# Y = np.sort(np.array(GHS2015.PopTot))\n",
    "\n",
    "# # By group\n",
    "col = 'rain_zone' # column\n",
    "area = 'Arid' # geography to distribut \n",
    "\n",
    "X = np.sort(np.array(GHS2000[GHS2000[col] == area].PopTot))\n",
    "Y = np.sort(np.array(GHS2015[GHS2015[col] == area].PopTot))\n",
    "\n",
    "print(len(X))\n",
    "print(len(Y))\n",
    "\n",
    "# Set Limits\n",
    "# X = X[(X < 10**7)]\n",
    "# Y = Y[(Y < 10**7)]\n",
    "\n",
    "print(len(X))\n",
    "print(len(Y))\n",
    "\n",
    "# Data for curve one\n",
    "X_lorenz = X.cumsum() / X.sum()\n",
    "X_lorenz = np.insert(X_lorenz, 0, 0)\n",
    "X_lorenz[0], X_lorenz[-1]\n",
    "\n",
    "# Data for curve two \n",
    "Y_lorenz = Y.cumsum() / Y.sum()\n",
    "Y_lorenz = np.insert(Y_lorenz, 0, 0)\n",
    "Y_lorenz[0], Y_lorenz[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lorenz Curve Plot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## Size & number\n",
    "sns.set(font_scale=3)\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=1,  figsize=(10, 10))\n",
    "\n",
    "\n",
    "# Curve Plots\n",
    "# Alpha for Botswana and S. Leone is 0.7, else 0.5\n",
    "ax1.scatter(np.arange(X_lorenz.size)/(X_lorenz.size-1), X_lorenz, \n",
    "           marker='.', color='Green', s=100, alpha = 0.7)\n",
    "\n",
    "ax1.scatter(np.arange(Y_lorenz.size)/(Y_lorenz.size-1), Y_lorenz, \n",
    "           marker='.', color='#ff01bc', s=100, alpha = 0.7)\n",
    "\n",
    "# Title\n",
    "plt.title(area)\n",
    "\n",
    "\n",
    "# Legend\n",
    "leg = ['GHS-Pop 2000', 'GHS-Pop 2015']\n",
    "plt.legend(leg,loc=2, markerscale=3)\n",
    "\n",
    "## line plot of of 90% 40% \n",
    "# ax1.plot([0.9,0.9], [0,1] , color='k', alpha = 0.25)\n",
    "# ax1.plot([0,1], [0.3,0.3] , color='k', alpha = 0.25)\n",
    "\n",
    "#remove ticks\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "\n",
    "# Grid\n",
    "plt.grid(b=True, color = 'k', alpha = 0.1, marker = '.')\n",
    "\n",
    "# plt.setp(ax1.xaxis.get_gridlines(), clip_path = [0,1])\n",
    "# plt.setp(ax1.yaxis.get_gridlines(), clip_path = [[0,0], [1,1]])\n",
    "plt.figure.frameon = True\n",
    "ax1.set_facecolor('White')\n",
    "\n",
    "## line plot of of 90% 40% \n",
    "ax1.plot([0.9,0.9], [0,1] , color='k', alpha = 1)\n",
    "#ax1.plot([0,1], [0.3,0.3] , color='k', alpha = 0.25)\n",
    "\n",
    "#fig.savefig('/Users/cascade/Desktop/'+area+'_Lorenz.png', dpi=700)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All countries\n",
    "\n",
    "countries = pd.Series(GHS2015.country, dtype=\"category\")\n",
    "\n",
    "countries = countries.cat.categories.tolist()\n",
    "countries[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Mega\n",
    "\n",
    "data1 = GHS2000[GHS2000.PopTot < 10**7]\n",
    "data2 = GHS2015[GHS2015.PopTot < 10**7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Descriptives and Zipfs Plots for all countries\n",
    "\n",
    "data1 = GHS2000[GHS2000.PopTot < 10**7]\n",
    "data2 = GHS2015[GHS2015.PopTot < 10**7]\n",
    "\n",
    "\n",
    "# all countires\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "arr = []\n",
    "\n",
    "\n",
    "for country in countries: \n",
    "    \n",
    "    test1 = data1[data1['country'] == country]\n",
    "    test2 = data2[data2['country'] == country]\n",
    "    \n",
    "    # counts\n",
    "    num2000= test1.PopTot.count()\n",
    "    num2015= test2.PopTot.count()\n",
    "    \n",
    "    #Median\n",
    "    m2000= test1.PopTot.median()\n",
    "    m2015= test2.PopTot.median()\n",
    "    \n",
    "    #gini\n",
    " \n",
    "    g2000 = gini(test1.PopTot)\n",
    "    g2015 = gini(test2.PopTot)\n",
    "\n",
    "    #zipf\n",
    "    X1_zipf = np.sort(test1.PopTot) #sort the values\n",
    "    Y1_zipf = list(range(1, len(X1_zipf)+1)) # make a range\n",
    "    Y1_zipf = Y1_zipf[::-1] # Re order range\n",
    "\n",
    "    X1_zipf_log = np.log(X1_zipf)\n",
    "    Y1_zipf_log = np.log(Y1_zipf)\n",
    "\n",
    "    X2_zipf = np.sort(test2.PopTot)\n",
    "    Y2_zipf = list(range(1, len(X2_zipf)+1))\n",
    "    Y2_zipf = Y2_zipf[::-1]\n",
    "\n",
    "    X2_zipf_log = np.log(X2_zipf)\n",
    "    Y2_zipf_log = np.log(Y2_zipf)\n",
    "    \n",
    "    fit1 = ss.linregress(X1_zipf_log, Y1_zipf_log)\n",
    "    fit2 = ss.linregress(X2_zipf_log, Y2_zipf_log)\n",
    "\n",
    "    #Fit\n",
    "\n",
    "    s2000 = fit1[0] # Slope 2000\n",
    "    p2000 = fit1[4] # p val 2000\n",
    "    \n",
    "    s2015 = fit2[0] # Slope 2015\n",
    "    p2015 = fit2[4] # p val 2015\n",
    "    \n",
    "    # Make dataframe\n",
    "    df[country] = (num2000, num2015, m2000, m2015, g2000, g2015, s2000, p2000, s2015, p2015)\n",
    "\n",
    "    # Zipf's law\n",
    "\n",
    "    ## Size & number\n",
    "    sns.set(font_scale=3)\n",
    "    fig, ax1 = plt.subplots(nrows=1, ncols=1,  figsize=(10, 10))\n",
    "\n",
    "    # Plot\n",
    "    plt.scatter(X1_zipf_log, Y1_zipf_log , marker='.', color='purple', s=100, alpha = 0.7)\n",
    "    plt.scatter(X2_zipf_log, Y2_zipf_log , marker='.', color='orange', s=100, alpha = 0.7)\n",
    "\n",
    "    # Legend\n",
    "    leg = ['GHS-Pop 2000', 'GHS-Pop 2015']\n",
    "    plt.legend(leg,loc=1, markerscale=3, facecolor = 'white', edgecolor = 'white')\n",
    "\n",
    "    # Fit Lines\n",
    "    sns.regplot(X1_zipf_log, Y1_zipf_log, color = 'purple')\n",
    "    sns.regplot(X2_zipf_log, Y2_zipf_log, color = 'orange')\n",
    "\n",
    "    # Title\n",
    "    plt.title(country)\n",
    "\n",
    "    # Labels\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "\n",
    "    # Set Ticks\n",
    "    plt.xticks([np.log(10**4), np.log(10**5), np.log(10**6), np.log(10**7)], \n",
    "               ['$10^4$', '$10^5$', '$10^6$', '$10^7$'])\n",
    "\n",
    "    plt.yticks([np.log(10), np.log(100), np.log(1000), np.log(10000),  np.log(100000)], \n",
    "               ['10', '$10^2$', '$10^3$', '$10^4$', '$10^5$'])\n",
    "\n",
    "    # Set Background Color\n",
    "    ax1.set_facecolor('White')\n",
    "\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([7,16])\n",
    "    #axes.set_xlim([min(X2_zipf_log), max(X2_zipf_log)])\n",
    "    axes.set_ylim([1,8])\n",
    "\n",
    "    ## Save Zipfs\n",
    "    fig.savefig('/Users/cascade/Desktop/Zipfs20190429/'+country+'_Zipf.png', dpi=300)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(data_analysis+'ALLCOUNTRIES_TABLE2_ERL20190429.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Africa\n",
    "\n",
    "print(len(data1))\n",
    "print(len(data2))\n",
    "\n",
    "print(data1.PopTot.median())\n",
    "print(data2.PopTot.median())\n",
    "\n",
    "print(gini(data1.PopTot))\n",
    "print(gini(data2.PopTot))\n",
    "\n",
    "\n",
    "#zipf\n",
    "X1_zipf = np.sort(data1.PopTot) #sort the values\n",
    "Y1_zipf = list(range(1, len(X1_zipf)+1)) # make a range\n",
    "Y1_zipf = Y1_zipf[::-1] # Re order range\n",
    "\n",
    "X1_zipf_log = np.log(X1_zipf)\n",
    "Y1_zipf_log = np.log(Y1_zipf)\n",
    "\n",
    "X2_zipf = np.sort(data2.PopTot)\n",
    "Y2_zipf = list(range(1, len(X2_zipf)+1))\n",
    "Y2_zipf = Y2_zipf[::-1]\n",
    "\n",
    "X2_zipf_log = np.log(X2_zipf)\n",
    "Y2_zipf_log = np.log(Y2_zipf)\n",
    "\n",
    "fit1 = ss.linregress(X1_zipf_log, Y1_zipf_log)\n",
    "fit2 = ss.linregress(X2_zipf_log, Y2_zipf_log)\n",
    "\n",
    "#Fit\n",
    "\n",
    "s2000 = fit1[0] # Slope 2000\n",
    "p2000 = fit1[4] # p val 2000\n",
    "\n",
    "s2015 = fit2[0] # Slope 2015\n",
    "p2015 = fit2[4] # p val 2015\n",
    "\n",
    "print('')\n",
    "print(s2000)\n",
    "print(p2000)\n",
    "print('')\n",
    "print(s2015)\n",
    "print(p2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = gpd.read_file(data_analysis+'GHS_POP_GPW42000_urbanmerge_PopTot.shp', driver = 'ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urban merge files still have duplicates\n",
    "\n",
    "# GHS is good\n",
    "GHS2000m = gpd.read_file(data_analysis+'GHS_POP_GPW42000_urbanmerge_PopTot.shp', driver = 'ESRI Shapefile')\n",
    "GHS2015m = gpd.read_file(data_analysis+'GHS_POP_GPW42015_urbanmerge_PopTot.shp', driver = 'ESRI Shapefile')\n",
    "\n",
    "\n",
    "## Load Data\n",
    "\n",
    "#WP 2015\n",
    "WP2015_dup = gpd.read_file(data_analysis+'AFR_PPP_2015_adj_v2_final20190122.shp')\n",
    "WP2015_Sudan = gpd.read_file(data_analysis+'AFR_PPP_2015_adj_v2_S_Sudan_1500c300_polyoverlapPopTot.shp')\n",
    "\n",
    "\n",
    "#WPE\n",
    "WPE2016_dup = gpd.read_file(data_analysis+'WPE_1KM_2016_final20190122.shp')\n",
    "WPE2016_Sudan = gpd.read_file(data_analysis+'WPE_1KM_2016_Pop_Clip_S_Sudan_1500c300_polyoverlapPopTot.shp')\n",
    "\n",
    "#LS \n",
    "LS2015_dup = gpd.read_file(data_analysis+'LS15_final20190122.shp')\n",
    "LS2015_Sudan = gpd.read_file(data_analysis+'LS15_w001001_Clip_S_Sudan_1500c300_polyoverlapPopTot.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "\n",
    "# Merge in South Sudan ... do each \n",
    "print(len(LS2015))\n",
    "print(len(LS2015_Sudan))\n",
    "frames = [LS2015, LS2015_Sudan]\n",
    "\n",
    "LS2015m = pd.concat(frames)\n",
    "print(len(LS2015m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GHS2000[GHS2000['osm_type'] == 'city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8368 - (len(GHS2000m[GHS2000m['osm_type'] == 'town']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = GHS2015[GHS2015['PopTot'] > 5*10**6]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(GHS2015.PopTot))\n",
    "np.std(np.log(GHS2015.PopTot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSM Raster PolyPoints\n",
    "\n",
    "This notebook contains analysis and visualizations for:\n",
    "\n",
    "1. Loading polygons from masked raster \n",
    "2. Loading in points from OSM\n",
    "3. Associating points with polygons\n",
    "\n",
    "Updated: 2018-11-21\n",
    "\n",
    "2018-11-30: Ran on WP1000c600 for 2000 & 2015 using 872 OSM cities with IDs and exported .shp polygons as\n",
    "20181130_africa1k_20**XX**_mask_1000c600_polypoints.shp. 739 foot prints for 2015 & 705 for 2000\n",
    "\n",
    "2018-12-04: Ran on WP1000c600 **with new function from Ryan** for 2000 & 2015 using 872 OSM cities with IDs and exported .shp polygons as\n",
    "20181204_africa1k_20**XX**_mask_1000c600_polypoints.shp. 721 foot prints for 2015 & 691 for 2000 (14 min)\n",
    "\n",
    "### NOTE on 2018-11-30 DROP polygon doubles at the VERY END\n",
    "\n",
    "### NOTE on 2018-12-04 Add array to function to capture osm points that are not found w/in polygons\n",
    "\n",
    "### Note on 2018-12-04 In loop, drop polygons as they are matched to lower the number "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEED TO FIND AWAY TO ASSOCIATE RASTER PIXELS AND POINTS WITH COUNTRIES Before we run giant for loop - show kelly problems in QGIS\n",
    "\n",
    "1. Can likely clip points by polygon geometry and chunk\n",
    "https://www.earthdatascience.org/courses/earth-analytics-python/spatial-data-vector-shapefiles/clip-vector-data-in-python-geopandas-shapely/\n",
    "\n",
    "2. Can likely clip polygons by countries\n",
    "\n",
    "https://gis.stackexchange.com/questions/168266/pyqgis-a-geometry-intersectsb-geometry-wouldnt-find-any-intersections\n",
    "\n",
    "#### updated 2018-11-21 Loop isn't that big and a good Africa basemap has a ton of polygons ... better to chunk later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load africa countries -- 762 polygons because of islands \n",
    "# Africa_poly = gpd.read_file(outfilepath+\"Africa_polys_test.shp\")\n",
    "# len(Africa_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import mapping\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import shape\n",
    "import ast\n",
    "from shapely.geometry import mapping\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in OSM and Polygons from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will build out folders later\n",
    "\n",
    "# data folder git will ignore\n",
    "#infilepath = \"/home/cascade/tana-crunch-cascade/projects/NTL/data/\" # git will ignore\n",
    "#outfilepath = \"/home/cascade/tana-crunch-cascade/projects/NTL/temp_data/\" # git will not ignore - NO BIG FILES \n",
    "\n",
    "# Local computer \n",
    "infilepath = '/Users/cascade/Github/NTL/data/raw/worldpop/Africa-1km-Population/'\n",
    "outfilepath = '/Users/cascade/Github/NTL/temp_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_points (file):\n",
    "    \"\"\" This function loads a csv of points and turns it into shapely points\"\"\"\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # creating a geometry column \n",
    "    geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]\n",
    "\n",
    "    # Coordinate reference system : WGS84\n",
    "    crs = {'init': 'epsg:4326'}\n",
    "\n",
    "    # Creating a Geographic data frame \n",
    "    point_gdf = gpd.GeoDataFrame(df, crs=crs, geometry=geometry)\n",
    "    \n",
    "    return point_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OSM Points\n",
    "osm_point_gdf = load_points(outfilepath+'20181129_osm_africa_cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(osm_point_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for buffering points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_buffer(gpd_df, raduis):\n",
    "    \"Function to make a shapely polygon buffer around a point\"\n",
    "   \n",
    "    new_gpd_df = gpd.GeoDataFrame()\n",
    "    arr = []\n",
    "    \n",
    "    for point in gpd_df['geometry']:\n",
    "        buffer = point.buffer(radius)\n",
    "        arr.append((buffer))\n",
    "    \n",
    "    new_gpd_df['id'] = gpd_df['id']\n",
    "    new_gpd_df['geometry'] = arr\n",
    "    \n",
    "    return new_gpd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0022522522522522522"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AGU 2018-12-04 - radius set to ~250m at the equator \n",
    "\n",
    "radius = 250*1/(111*1000)\n",
    "radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "osm_buffer_gdf = point_buffer(osm_point_gdf, radius)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out shape file buffer 2018-12-04\n",
    "#test.to_file(outfilepath+'test_250mBuffer.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for searching if a point is within a polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_point (poly, point):\n",
    "    \"\"\"\n",
    "    This function will check if points are inside polygons if given two gpd dataframes with points and polygons\n",
    "    Returns point ids, point geometry, polygon index # and polygon geometry\n",
    "    \"\"\"\n",
    "    \n",
    "    out_arr = [] #return an array <<< ---------------- ASK RYAN IF BETTER DO USE DICT \n",
    "    \n",
    "    for index_point, row_point in point.iterrows():\n",
    "        for index_poly, row_poly in poly.iterrows():\n",
    "            if row_point['geometry'].within(row_poly['geometry']):\n",
    "                point_id = row_point['id']\n",
    "                point_geom = mapping(row_point['geometry']) # makes a dict w/ keys : type and cood\n",
    "                poly_id = index_poly\n",
    "                poly_geom = mapping(row_poly['geometry']) # makes a dict w/ keys : type and cood\n",
    "                \n",
    "                out_arr.append((point_id, \n",
    "                                point_geom, \n",
    "                                poly_id, \n",
    "                                poly_geom))\n",
    "\n",
    "    return out_arr\n",
    "\n",
    "# Note 2018-11-30 update arr to gpd_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for polygon intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_buffer (point_buffer, poly_raster):\n",
    "    \"\"\"\n",
    "    This function will check if point buffers intersect with polygons \n",
    "    if given two gpd dataframes with point buffers and polygons\n",
    "    Returns point ids, point geometry, polygon index #, and polygon geometry in a geopandas DF.\n",
    "    It goes faster if smaller list goes first\n",
    "    \"\"\"\n",
    "    \n",
    "    # make arrays to fill\n",
    "    osm_id_arr = [] \n",
    "    FID_arr = [] \n",
    "    poly_geom_arr = []\n",
    "    \n",
    "    for index_point_buffer, row_point_buffer in point_buffer.iterrows():\n",
    "        for index_poly_raster, row_poly_raster in poly_raster.iterrows():\n",
    "            if row_point_buffer['geometry'].intersects(row_poly_raster['geometry']):\n",
    "                osm_id = row_point_buffer['id']\n",
    "                poly_id = row_poly_raster['FID']\n",
    "                poly_geom = shape(mapping(row_poly_raster['geometry'])) # make polygon \n",
    "\n",
    "                osm_id_arr.append((osm_id))\n",
    "                FID_arr.append((poly_id))\n",
    "                poly_geom_arr.append((poly_geom))\n",
    "    \n",
    "    # put results into a geopandas df\n",
    "    new_gpd_df = gpd.GeoDataFrame()\n",
    "    new_gpd_df['osm_id'] = osm_id_arr\n",
    "    new_gpd_df['FID'] = FID_arr\n",
    "    new_gpd_df['geometry'] = poly_geom_arr\n",
    "    \n",
    "    return new_gpd_df\n",
    "\n",
    "# Note 2018-11-30 update arr to gpd_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Polygon\n",
    "\n",
    "WP2000_poly = gpd.read_file(outfilepath+'20181204_africa1k_2000_mask_1000c600_poly.shp')\n",
    "WP2015_poly = gpd.read_file(outfilepath+'20181204_africa1k_2015_mask_1000c600_poly.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22029\n",
      "15055\n",
      "872\n"
     ]
    }
   ],
   "source": [
    "print(len(WP2015_poly))\n",
    "print(len(WP2000_poly))\n",
    "print(len(osm_buffer_gdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time is: 1293.72336435318s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "checkpoint = time.time()\n",
    "\n",
    "WP2015_polybuff = poly_buffer(osm_buffer_gdf, WP2015_poly)\n",
    "\n",
    "print(\"elapsed time is: {}s\".format(time.time()-checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "721"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(WP2015_polybuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WP2015_polybuff.to_file(outfilepath+'20181204_africa1k_2015_mask_1000c600_polypoints.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to take dicts and make shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from shapely.geometry import shape\n",
    "\n",
    "def arr_gpd(gpd_df, incolname, newcolname):\n",
    "    \"\"\"Function takes a geopandas dataframe with dicts and returns proper geometry to make shapefiles\"\"\"\n",
    "    arr = []\n",
    "\n",
    "    for i in gpd_df[incolname]:\n",
    "        i = shape(i)\n",
    "        arr.append((i))\n",
    "\n",
    "    # for poly in polypoints_2000_df.iloc[:,6]:\n",
    "    #     poly = shape(ast.literal_eval(poly))\n",
    "    #     test.append = (poly)\n",
    "\n",
    "    #polypoints_2020_df['poly_geom'] = polypoints_2020_df['poly_geom'].apply(ast.literal_eval())\n",
    "    gpd_df[newcolname] = arr\n",
    "    \n",
    "    return gpd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WP2015_polypoints_df.to_file(outfilepath+'20181130_africa1k_2015_mask_1000c600_polypoints.shp', driver='ESRI Shapefile')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a function to check if points are in poly for lists of poly and points\n",
    "# needs geopandas data frame with point and poly geometry \n",
    "\n",
    "# def poly_point (poly, point):\n",
    "#     \"\"\"\n",
    "#     This function will check if points are inside polygons if given two gpds with points and polygons\n",
    "#     Returns city names or no list \n",
    "#     \"\"\"\n",
    "    \n",
    "#     out_arr = [] #return an array <<< ---------------- ASK RYAN IF BETTER DO USE DICT \n",
    "    \n",
    "#     for index_point, row_point in point.iterrows():\n",
    "#         for index_poly, row_poly in poly.iterrows():\n",
    "#             if row_point['geometry'].within(row_poly['geometry']):\n",
    "#                 country = row_point['Country']\n",
    "#                 city = row_point['City']\n",
    "#                 point_id = row_point['Id']\n",
    "#                 point_geom = mapping(row_point['geometry']) # makes a dict w/ keys : type and cood\n",
    "#                 poly_id = index_poly\n",
    "#                 poly_geom = mapping(row_poly['geometry']) # makes a dict w/ keys : type and cood\n",
    "                \n",
    "#                 out_arr.append((country, \n",
    "#                                 city, \n",
    "#                                 point_id, \n",
    "#                                 point_geom, \n",
    "#                                 poly_id, \n",
    "#                                 poly_geom))\n",
    "# #             else:\n",
    "# #                 test.append('no')\n",
    "#     return out_arr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

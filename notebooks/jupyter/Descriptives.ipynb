{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NoteBook to Make Descriptives\n",
    "\n",
    "This notebook is for looking at final population zonal stats data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterstats import zonal_stats\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from functools import reduce\n",
    "import squarify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_search(gpd_df, city_list, country):\n",
    "    \"\"\" function will print out city name and population for a subset of a gridded dataset gpd\n",
    "    requires data frame, list of cities, and country of interest\n",
    "    \"\"\"\n",
    "    gpd_df_sub = gpd_df[gpd_df['country'] == country]\n",
    "    \n",
    "    for index, row in gpd_df_sub.iterrows():\n",
    "        for city in city_list:\n",
    "            if row['city'] == city:\n",
    "                print(city)\n",
    "                print(round(row['PopTot']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_id(gpd_df):\n",
    "    \"\"\"\n",
    "    Function makes a new col with a unique lat-lon string to identify each osm point & drops duplicates\n",
    "    Function also makes\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    print(gpd_df.shape)\n",
    "    \n",
    "    lat_string = gpd_df.lat.astype(str)\n",
    "    lon_string = gpd_df.lon.astype(str)\n",
    "    gpd_df['str_id'] = lat_string.astype(str)+lon_string.astype(str)\n",
    "    \n",
    "    print(gpd_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dup_drop(gpd_in, col, keep_dup):\n",
    "    \"\"\" \n",
    "    function drops duplicates based on a column from a pd data frame\n",
    "    requires pd df out string, pd df, col name, and which dup to keep\n",
    "    returns new gpd_df\n",
    "    \"\"\"\n",
    "    \n",
    "    gpd_out = gpd.GeoDataFrame()\n",
    "    \n",
    "    print(gpd_in.shape)\n",
    "    \n",
    "    gpd_out = gpd_in.drop_duplicates(col, keep = keep_dup)\n",
    "    \n",
    "    print(gpd_out.shape)\n",
    "\n",
    "    return gpd_out\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_merge(df_left, df_right):\n",
    "    \n",
    "    pd_out = pd.DataFrame()\n",
    "    pd_out = pd.merge(df_left[['str_id', 'PopTot']], df_right[['str_id', 'PopTot']], on='str_id', how = 'inner')\n",
    "    \n",
    "    left_pop = pd_out.PopTot_x.astype(str)\n",
    "    right_pop = pd_out.PopTot_y.astype(str)\n",
    "    pd_out['pop_id'] = left_pop.astype(str)+right_pop.astype(str)\n",
    "\n",
    "    return pd_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_X_gt_x(data, X=None):\n",
    "    n_data = len(data)\n",
    "    if X is None:\n",
    "        X = data.unique()\n",
    "    return X, pd.Series([sum(data>=x)/n_data for x in X ])\n",
    "\n",
    "def p_X_lt_x(data, X=None):\n",
    "    n_data = len(data)\n",
    "    if X is None:\n",
    "        X = data.unique()\n",
    "    return X, pd.Series([sum(data<=x)/n_data for x in X ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "\n",
    "data_raw = '/Users/cascade/Github/NTL/data/raw/'\n",
    "data_temp = '/Users/cascade/Github/NTL/temp_data/'\n",
    "data_interim = '/Users/cascade/Github/NTL/data/interim/'\n",
    "ms_data = '/Users/cascade/Github/NTL/temp_data/MS_Data/'\n",
    "erl_data = '/Users/cascade/Github/NTL/temp_data/ERL_data/'\n",
    "downloads = '/Users/cascade/Downloads/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "GHS2000 = gpd.read_file(erl_data+'GHS_POP_GPW42000_final20190122.shp')\n",
    "GHS2015 = gpd.read_file(erl_data+'GHS_POP_GPW42015_final20190122.shp')\n",
    "WP2000 = gpd.read_file(erl_data+'AFR_PPP_2000_adj_v2_final20190122.shp')\n",
    "WP2015 = gpd.read_file(erl_data+'AFR_PPP_2015_adj_v2_final20190122.shp')\n",
    "LS2015 = gpd.read_file(erl_data+'WPE_1KM_2016_final20190122.shp')\n",
    "WPE2016 = gpd.read_file(erl_data+'LS15_final20190122.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of datasets\n",
    "\n",
    "datasets_in = [GHS2000, GHS2015, WP2000, WP2015, LS2015, WPE2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GHS2000.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add regions\n",
    "\n",
    "Add new column that adds the region for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### List of African Countries from the UN in OSM wiki\n",
    "\n",
    "Northern_Africa = (['Algeria', 'Egypt', 'Libya', 'Morocco', 'Tunisia', 'Western Sahara'], 'Northern_Africa')\n",
    "\n",
    "Eastern_Africa = ([\n",
    "    'Burundi',\n",
    "    'Comoros',\n",
    "    'Djibouti',\n",
    "    'Eritrea',\n",
    "    'Ethiopia',\n",
    "    'Kenya',\n",
    "    'Madagascar',\n",
    "    'Malawi',\n",
    "    'Mauritius',\n",
    "    #Mayotte,\n",
    "    'Mozambique',\n",
    "    'Réunion',\n",
    "    'Rwanda',\n",
    "    'Somalia',\n",
    "    'Sudan',\n",
    "    'Uganda',\n",
    "    'Tanzania',\n",
    "    'Zambia',\n",
    "    'Zimbabwe'], 'Eastern_Africa')\n",
    "    \n",
    "Middle_Africa = ([\n",
    "    'Angola',\n",
    "    'Cameroon',\n",
    "    'Central African Republic',\n",
    "    'Chad',\n",
    "    'Congo-Brazzaville',\n",
    "    'Congo-Kinshasa',\n",
    "    'Equatorial Guinea',\n",
    "    'Gabon',\n",
    "    'Sao Tome and Principe'], 'Middle_Africa')\n",
    "    \n",
    "Southern_Africa = ([\n",
    "    'Botswana',\n",
    "    'Lesotho',\n",
    "    'Namibia',\n",
    "    'South Africa',\n",
    "    'Swaziland'], 'Southern_Africa')\n",
    "    \n",
    "Western_Africa = ([\n",
    "    'Benin',\n",
    "    'Burkina Faso',\n",
    "    'Cape Verde',\n",
    "    'Côte d\\'Ivoire',\n",
    "    'Gambia',\n",
    "    'Ghana',\n",
    "    'Guinea',\n",
    "    'Guinea-Bissau',\n",
    "    'Liberia',\n",
    "    'Mali',\n",
    "    'Mauritania',\n",
    "    'Niger',\n",
    "    'Nigeria',\n",
    "    'Senegal',\n",
    "    'Sierra Leone',\n",
    "    'Togo'], 'Western_Africa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [Northern_Africa, Western_Africa, Eastern_Africa, Southern_Africa, Middle_Africa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region(gpd_df, regions_list):\n",
    "    \"Function adds a new col to a df based on region\"\n",
    "    arr =[]\n",
    "    for region in regions_list:\n",
    "        for country in region[0]:\n",
    "            for i, row in gpd_df.iterrows():\n",
    "                if row['country'] == country:\n",
    "                    #row['region'] = region[1] \n",
    "                    #df_copy.iloc[i] = row\n",
    "                    #region[1]\n",
    "                    arr.append(region[1])\n",
    "    gpd_df['region'] = arr\n",
    "    \n",
    "    return gpd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets_in:\n",
    "    dataset = region(dataset, regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  AZE to Rain Zones\n",
    "\n",
    "create new column for each dataset that includes a cities rain climate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group my rainfall zone\n",
    "\n",
    "arid = (['Temperate / arid', \n",
    "         'Subtropic - warm / arid', \n",
    "         'Subtropic - cool / arid', \n",
    "         'Tropic - warm / arid',\n",
    "         'Tropic - cool / arid'], 'Arid')\n",
    "\n",
    "semi_arid = (['Temperate / Semi-arid', \n",
    "              'Subtropic - warm / semiarid', \n",
    "              'Subtropic - cool / semiarid',\n",
    "              'Tropic - warm / semiarid', \n",
    "              'Tropic - cool / semiarid'], 'Semi-arid')    \n",
    "\n",
    "sub_humid = (['Temperate / sub-humid', \n",
    "              'Subtropic - warm / subhumid', \n",
    "              'Subtropic - cool / subhumid',\n",
    "              'Tropic - warm / subhumid', \n",
    "              'Tropic - cool / subhumid'], 'Sub-humid')\n",
    "\n",
    "humid = (['Temperate / humid', \n",
    "          'Subtropic - warm / humid', \n",
    "          'Subtropic - cool / humid', \n",
    "          'Tropic - warm / humid',\n",
    "          'Tropic - cool / humid'], 'Humid')\n",
    "\n",
    "boreal = (['Boreal'], 'Boreal')\n",
    "\n",
    "na = (['NoClass', '0'], 'NA')\n",
    "\n",
    "rain_list = [arid, semi_arid, sub_humid, humid, boreal, na]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rain_zone(gpd_df, rain_list):\n",
    "    \"function adds a new col to a gpd_df based on rain fall zone\"\n",
    "    arr =[]\n",
    "    for rain_zone in rain_list:\n",
    "        for aez in rain_zone[0]:\n",
    "            for i, row in gpd_df.iterrows():\n",
    "                if row['aez_class'] == aez:\n",
    "                    arr.append(rain_zone[1])\n",
    "                \n",
    "    gpd_df['rain_zone'] = arr\n",
    "    \n",
    "    return gpd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets_in:\n",
    "    dataset = rain_zone(dataset, rain_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distrubutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk by city size figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicate FIDs (Polygons) and <5000 people \n",
    "\n",
    "print('1---WP2015---') # World Pop 2015\n",
    "\n",
    "# drop FID\n",
    "print(len(WP2015))\n",
    "WP2015 = WP2015.drop_duplicates('FID', keep = 'first')\n",
    "print(len(WP2015))\n",
    "\n",
    "# drop <5000\n",
    "WP2015 = WP2015[WP2015['PopTot'] > 5000]\n",
    "print(len(WP2015))\n",
    "\n",
    "print('2---LS2015---') # LandScan 2015\n",
    "# drop FID\n",
    "print(len(LS2015))\n",
    "LS2015 = LS2015.drop_duplicates('FID', keep = 'first')\n",
    "print(len(LS2015))\n",
    "\n",
    "# drop <5000\n",
    "LS2015 = LS2015[LS2015['PopTot'] > 5000]\n",
    "print(len(LS2015))\n",
    "\n",
    "print('3---WPE2016---') # WPE 2016\n",
    "# drop FID\n",
    "print(len(WPE2016))\n",
    "WPE2016 = WPE2016.drop_duplicates('FID', keep = 'first')\n",
    "print(len(WPE2016))\n",
    "\n",
    "# drop <5000\n",
    "WPE2016 = WPE2016[WPE2016['PopTot'] > 5000]\n",
    "print(len(WPE2016))\n",
    "\n",
    "print('4---GHS2015---') # GHS 2015\n",
    "# drop FID\n",
    "print(len(GHS2015))\n",
    "GHS2015 = GHS2015.drop_duplicates('FID', keep = 'first')\n",
    "print(len(GHS2015))\n",
    "\n",
    "# drop <5000\n",
    "GHS2015 = GHS2015[GHS2015['PopTot'] > 5000]\n",
    "print(len(GHS2015))\n",
    "\n",
    "print('5---GHS2000---') # GHS 2000\n",
    "# drop FID\n",
    "print(len(GHS2000))\n",
    "GHS2000 = GHS2000.drop_duplicates('FID', keep = 'first')\n",
    "print(len(GHS2000))\n",
    "\n",
    "# drop <5000\n",
    "GHS2000 = GHS2000[GHS2000['PopTot'] > 5000]\n",
    "print(len(GHS2000))\n",
    "\n",
    "      \n",
    "print('6---WP2000---') # World Pop 2000\n",
    "\n",
    "# drop FID\n",
    "print(len(WP2000))\n",
    "WP2000 = WP2000.drop_duplicates('FID', keep = 'first')\n",
    "print(len(WP2000))\n",
    "\n",
    "# drop <5000\n",
    "WP2000 = WP2000[WP2000['PopTot'] > 5000]\n",
    "print(len(WP2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk by country \n",
    "\n",
    "WP2015_Nigeria = WP2015[WP2015['country']=='Ghana']\n",
    "LS2015_Nigeria = LS2015[LS2015['country']=='Ghana']\n",
    "GHS2015_Nigeria = GHS2015[GHS2015['country']=='Ghana']\n",
    "WPE2016_Nigeria = WPE2016[WPE2016['country']=='Ghana']\n",
    "\n",
    "print(len(WP2015_Nigeria))\n",
    "print(len((LS2015_Nigeria)))\n",
    "print(len((GHS2015_Nigeria)))\n",
    "print(len((WPE2016_Nigeria)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WP 2015 Chunks\n",
    "WP2015_50k = WP2015.loc[(WP2015['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(WP2015_50k)\n",
    "\n",
    "WP2015_100k = WP2015.loc[(WP2015['PopTot'] > 5*10**4) & (WP2015['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(WP2015_100k)\n",
    "\n",
    "WP2015_250k = WP2015.loc[(WP2015['PopTot'] > 10**5) & (WP2015['PopTot'] <= 2.5*10**5), 'PopTot'].sum()\n",
    "print(WP2015_250k)\n",
    "\n",
    "WP2015_500k = WP2015.loc[(WP2015['PopTot'] > 2.5*10**5) & (WP2015['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(WP2015_500k)\n",
    "\n",
    "WP2015_1m = WP2015.loc[(WP2015['PopTot'] > 5*10**5) & (WP2015['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(WP2015_1m)\n",
    "\n",
    "WP2015_5m = WP2015.loc[(WP2015['PopTot'] > 10**6) & (WP2015['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(WP2015_5m)\n",
    "\n",
    "WP2015_5mplus = WP2015.loc[(WP2015['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(WP2015_5mplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LS 2015 Chunks \n",
    "\n",
    "LS2015_50k = LS2015.loc[(LS2015['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(LS2015_50k)\n",
    "\n",
    "LS2015_100k = LS2015.loc[(LS2015['PopTot'] > 5*10**4) & (LS2015['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(LS2015_100k)\n",
    "\n",
    "LS2015_250k = LS2015.loc[(LS2015['PopTot'] > 10**5) & (LS2015['PopTot'] <= 2.5*10**5), 'PopTot'].sum()\n",
    "print(LS2015_250k)\n",
    "\n",
    "LS2015_500k = LS2015.loc[(LS2015['PopTot'] > 2.5*10**5) & (LS2015['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(LS2015_500k)\n",
    "\n",
    "LS2015_1m = LS2015.loc[(LS2015['PopTot'] > 5*10**5) & (LS2015['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(LS2015_1m)\n",
    "\n",
    "LS2015_5m = LS2015.loc[(LS2015['PopTot'] > 10**6) & (LS2015['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(LS2015_5m)\n",
    "\n",
    "LS2015_5mplus = LS2015.loc[(LS2015['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(LS2015_5mplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GHS 2015 Chunks\n",
    "\n",
    "GHS2015_50k = GHS2015.loc[(GHS2015['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(GHS2015_50k)\n",
    "\n",
    "GHS2015_100k = GHS2015.loc[(GHS2015['PopTot'] > 5*10**4) & (GHS2015['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(GHS2015_100k)\n",
    "\n",
    "GHS2015_250k = GHS2015.loc[(GHS2015['PopTot'] > 10**5) & (GHS2015['PopTot'] <= 2.5*10**5), 'PopTot'].sum()\n",
    "print(GHS2015_250k)\n",
    "\n",
    "GHS2015_500k = GHS2015.loc[(GHS2015['PopTot'] > 2.5*10**5) & (GHS2015['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(GHS2015_500k)\n",
    "\n",
    "GHS2015_1m = GHS2015.loc[(GHS2015['PopTot'] > 5*10**5) & (GHS2015['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(GHS2015_1m)\n",
    "\n",
    "GHS2015_5m = GHS2015.loc[(GHS2015['PopTot'] > 10**6) & (GHS2015['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2015_5m)\n",
    "\n",
    "GHS2015_5mplus = GHS2015.loc[(GHS2015['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2015_5mplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WPE 2016 Chunks\n",
    "WPE2016_50k = WPE2016.loc[(WPE2016['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(WPE2016_50k)\n",
    "\n",
    "WPE2016_100k = WPE2016.loc[(WPE2016['PopTot'] > 5*10**4) & (WPE2016['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(WPE2016_100k)\n",
    "\n",
    "WPE2016_250k = WPE2016.loc[(WPE2016['PopTot'] > 10**5) & (WPE2016['PopTot'] <= 2.5*10**5), 'PopTot'].sum()\n",
    "print(WPE2016_250k)\n",
    "\n",
    "WPE2016_500k = WPE2016.loc[(WPE2016['PopTot'] > 2.5*10**5) & (WPE2016['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(WPE2016_500k)\n",
    "\n",
    "WPE2016_1m = WPE2016.loc[(WPE2016['PopTot'] > 5*10**5) & (WPE2016['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(WPE2016_1m)\n",
    "\n",
    "WPE2016_5m = WPE2016.loc[(WPE2016['PopTot'] > 10**6) & (WPE2016['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(WPE2016_5m)\n",
    "\n",
    "WPE2016_5mplus = WPE2016.loc[(WPE2016['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(WPE2016_5mplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WP 2000 Chunks\n",
    "WP2000_50k = WP2000.loc[(WP2000['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(WP2000_50k)\n",
    "\n",
    "WP2000_100k = WP2000.loc[(WP2000['PopTot'] > 5*10**4) & (WP2000['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(WP2000_100k)\n",
    "\n",
    "WP2000_250k = WP2000.loc[(WP2000['PopTot'] > 10**5) & (WP2000['PopTot'] <= 2.5*10**5), 'PopTot'].sum()\n",
    "print(WP2000_250k)\n",
    "\n",
    "WP2000_500k = WP2000.loc[(WP2000['PopTot'] > 2.5*10**5) & (WP2000['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(WP2000_500k)\n",
    "\n",
    "WP2000_1m = WP2000.loc[(WP2000['PopTot'] > 5*10**5) & (WP2000['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(WP2000_1m)\n",
    "\n",
    "WP2000_5m = WP2000.loc[(WP2000['PopTot'] > 10**6) & (WP2000['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(WP2000_5m)\n",
    "\n",
    "WP2000_5mplus = WP2000.loc[(WP2000['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(WP2000_5mplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHS 2000 Chunks\n",
    "GHS2000_50k = GHS2000.loc[(GHS2000['PopTot'] <= 5*10**4), 'PopTot'].sum()\n",
    "print(GHS2000_50k)\n",
    "\n",
    "GHS2000_100k = GHS2000.loc[(GHS2000['PopTot'] > 5*10**4) & (GHS2000['PopTot'] <= 10**5), 'PopTot'].sum()\n",
    "print(GHS2000_100k)\n",
    "\n",
    "GHS2000_250k = GHS2000.loc[(GHS2000['PopTot'] > 10**5) & (GHS2000['PopTot'] <= 2.5*10**5), 'PopTot'].sum()\n",
    "print(GHS2000_250k)\n",
    "\n",
    "GHS2000_500k = GHS2000.loc[(GHS2000['PopTot'] > 2.5*10**5) & (GHS2000['PopTot'] <= 5*10**5), 'PopTot'].sum()\n",
    "print(GHS2000_500k)\n",
    "\n",
    "GHS2000_1m = GHS2000.loc[(GHS2000['PopTot'] > 5*10**5) & (GHS2000['PopTot'] <= 10**6), 'PopTot'].sum()\n",
    "print(GHS2000_1m)\n",
    "\n",
    "GHS2000_5m = GHS2000.loc[(GHS2000['PopTot'] > 10**6) & (GHS2000['PopTot'] <= 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2000_5m)\n",
    "\n",
    "GHS2000_5mplus = GHS2000.loc[(GHS2000['PopTot'] > 5*10**6), 'PopTot'].sum()\n",
    "print(GHS2000_5mplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentages\n",
    "\n",
    "WP2000_chunks = [WP2000_50k, WP2000_100k, WP2000_250k, WP2000_500k, WP2000_1m, WP2000_5m, WP2000_5mplus]\n",
    "WP2015_chunks = [WP2015_50k, WP2015_100k, WP2015_250k, WP2015_500k, WP2015_1m, WP2015_5m, WP2015_5mplus]\n",
    "\n",
    "GHS2000_chunks = [GHS2000_50k, GHS2000_100k, GHS2000_250k, GHS2000_500k, GHS2000_1m, GHS2000_5m, GHS2000_5mplus]\n",
    "GHS2015_chunks = [GHS2015_50k, GHS2015_100k, GHS2015_250k, GHS2015_500k, GHS2015_1m, GHS2015_5m, GHS2015_5mplus]\n",
    "\n",
    "LS2015_chunks = [LS2015_50k, LS2015_100k, LS2015_250k, LS2015_500k, LS2015_1m, LS2015_5m, LS2015_5mplus]\n",
    "\n",
    "WPE2016_chunks = [WPE2016_50k, WPE2016_100k, WPE2016_250k, WPE2016_500k, WPE2016_1m, WPE2016_5m, WPE2016_5mplus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_in = [GHS2000, GHS2015, WP2000, WP2015, LS2015, WPE2016]\n",
    "\n",
    "data_chunks = [GHS2000_chunks, GHS2015_chunks, WP2000_chunks, WP2015_chunks, LS2015_chunks, WPE2016_chunks] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "GHS2000_chunks_pct = np.around(GHS2000_chunks / GHS2000.PopTot.sum() * 100, 1)\n",
    "GHS2015_chunks_pct = np.around(GHS2015_chunks / GHS2015.PopTot.sum(), 1)\n",
    "\n",
    "WP2000_chunks_pct = np.around(WP2000_chunks / WP2000.PopTot.sum() * 100, 1)\n",
    "WP2015_chunks_pct = np.around(WP2015_chunks / WP2015.PopTot.sum() * 100, 1)\n",
    "\n",
    "LS2015_chunks_pct = np.around(LS2015_chunks / LS2015.PopTot.sum() * 100, 1)\n",
    "WPE2016_chunks_pct = np.around(WPE2016_chunks / WPE2016.PopTot.sum() * 100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Square Plot\n",
    "\n",
    "http://gvallver.perso.univ-pau.fr/?p=700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.around(WP2015_chunks))\n",
    "print(WP2015_chunks_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Data \n",
    "\n",
    "data = np.around(LS2015_chunks)\n",
    "pct = LS2015_chunks_pct\n",
    "chunks = ['<50K:', '50-100K: ', '100-150K: ','250-500K: ', '500K-1M: ', '1-5M: ', '>5M: ']\n",
    "\n",
    "labels = [chunks[0]+'\\n'+str(pct[0])+'%',\n",
    "         chunks[1]+'\\n'+str(pct[1])+'%',\n",
    "         chunks[2]+'\\n'+str(pct[2])+'%',\n",
    "         chunks[3]+'\\n'+str(pct[3])+'%',\n",
    "         chunks[4]+'\\n'+str(pct[4])+'%',\n",
    "         chunks[5]+'\\n'+str(pct[5])+'%',\n",
    "         chunks[6]+'\\n'+str(pct[6])+'%'\n",
    "         ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for chunk in chunks:\n",
    "#     for pct in WP2015_chunks_pct:\n",
    "#         label = chunk + '\\n' + str(pct) + '%'\n",
    "#         labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Colors\n",
    "norm = matplotlib.colors.Normalize(vmin=min(data), vmax=max(data))\n",
    "colors = [matplotlib.cm.Blues_r(norm(value)) for value in data]\n",
    "\n",
    "# Create Plot\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "fig.suptitle(\"\", fontsize=20)\n",
    "ax = fig.add_subplot(111, aspect='equal')\n",
    "ax = squarify.plot(data, color = colors, label=labels, ax=ax, alpha = 0.7)\n",
    "\n",
    "# Remove ticks\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title('WorldPop 2015 \\n Urban Settlments Distribution')\n",
    "\n",
    "# color bar\n",
    "bar_number = data/(10**6)\n",
    "\n",
    "# create dummy invisible image with a color map\n",
    "img = plt.imshow([bar_number], cmap='Blues_r')\n",
    "img.set_visible(False)\n",
    "fig.colorbar(img, orientation=\"vertical\", shrink=.96)\n",
    "fig.text(.76, .9, \"Population in Millions\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "# labels = {'<50K': WP2015_50k, '50-100K': WP2015_100k, '100-150K':WP2015_250k,\n",
    "#     '250-500K' : WP2015_500k, '500K-1M' : WP2015_1m, '1-5M' : WP2015_5m, '>5M' : WP2015_5mplus\n",
    "#              }\n",
    "#labels = WP2000_chunks_pct\n",
    "\n",
    "labels = ['<50K = '+str(WP2015_chunks_pct[0])+'%', ]\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Colors \n",
    "# cmap = matplotlib.cm.Greens_r\n",
    "# mini, maxi = WP2015_chunks_pct.min(), WP2015_chunks_pct.max()\n",
    "# norm = matplotlib.colors.Normalize(vmin=mini, vmax=maxi)\n",
    "# colors = [cmap(norm(value)) for value in WP2015_chunks_pct]\n",
    "#colors[1] = \"#FBFCFE\"\n",
    "\n",
    "norm = matplotlib.colors.Normalize(vmin=min(WP2015_chunks_pct), vmax=max(WP2015_chunks_pct))\n",
    "colors = [matplotlib.cm.Greys_r(norm(value)) for value in WP2015_chunks_pct]\n",
    "\n",
    "\n",
    "# make plot\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "fig.suptitle(\"\", fontsize=20)\n",
    "ax = fig.add_subplot(111, aspect=\"equal\")\n",
    "ax = squarify.plot(WP2000_chunks_pct, color = colors, label=labels, ax=ax, alpha=0.9)\n",
    "# color = colors, labels = labels \n",
    "\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"WorldPop 2015 Urban Settlement Distribution for Africa\", fontsize=14)\n",
    "\n",
    "# color bar\n",
    "# create dummy invisible image with a color map\n",
    "# img = plt.imshow([df2.p11_pop], cmap=cmap)\n",
    "# img.set_visible(False)\n",
    "# fig.colorbar(img, orientation=\"vertical\", shrink=.96)\n",
    "\n",
    "# fig.text(.76, .9, \"Population\", fontsize=14)\n",
    "# fig.text(.5, 0.1,\n",
    "#          \"Superficie totale %d km2, Population de la CAPP : %d hab\" % (df2.superf.sum(), df2.p11_pop.sum()),\n",
    "#          fontsize=14,\n",
    "#          ha=\"center\")\n",
    "# fig.text(.5, 0.07,\n",
    "#          \"Source : http://opendata.agglo-pau.fr/\",\n",
    "#          fontsize=14,\n",
    "#          ha=\"center\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.plotly as py\n",
    "# import plotly.tools as tls\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dictionary = plt.figure()\n",
    "\n",
    "WP2015_bar = {'<50K':WP2015_50k, '50-100K': WP2015_100k, '100-150K':WP2015_250k,\n",
    "    '250-500K' : WP2015_500k, '500K-1M' : WP2015_1m, '1-5M' : WP2015_5m, '>5M' : WP2015_5mplus\n",
    "             }\n",
    "\n",
    "# WP2000_bar = {u'Label0':WP2000_50k, u'Label1': WP2000_100k, u'Label2':WP2000_250k,\n",
    "#     u'Label3' : WP2000_500k, u'Label4' : WP2000_1m, u'Label5' : WP2000_5m, u'Label6' : WP2000_5mplus\n",
    "#     }\n",
    "\n",
    "LS2015_bar = {u'Label0':LS2015_50k, u'Label1': LS2015_100k, u'Label2':LS2015_250k,\n",
    "    u'Label3' : LS2015_500k, u'Label4' : LS2015_1m, u'Label5' : LS2015_5m, u'Label6' : LS2015_5mplus\n",
    "    }\n",
    "\n",
    "GHS2015_bar = {u'Label0':GHS2015_50k, u'Label1': GHS2015_100k, u'Label2':GHS2015_250k,\n",
    "    u'Label3' : GHS2015_500k, u'Label4' : GHS2015_1m, u'Label5' : GHS2015_5m, u'Label6' : GHS2015_5mplus\n",
    "    }\n",
    "\n",
    "WPE2016_bar = {u'Label0':WPE2016_50k, u'Label1': WPE2016_100k, u'Label2':WPE2016_250k,\n",
    "    u'Label3' : WPE2016_500k, u'Label4' : WPE2016_1m, u'Label5' : WPE2016_5m, u'Label6' : WPE2016_5mplus\n",
    "   }\n",
    "\n",
    "# make plot\n",
    "sns.set(font_scale=3)\n",
    "x = [0,1,2,3,4,5,6]\n",
    "y = [0-.2,1-.2,2-.2,3-.2,4-.2,5-.2,6-.2]\n",
    "z = [0-.4,1-.4,2-.4,3-.4,4-.4,5-.4,6-.4]\n",
    "a = [0+.2,1+.2,2+.2,3+.2,4+.2,5+.2,6+.2]\n",
    "\n",
    "\n",
    "\n",
    "plt.bar(x, WP2015_bar.values(), width=0.2, align='center', alpha  = 0.5, color = 'Blue')\n",
    "\n",
    "plt.bar(y, LS2015_bar.values(), width=0.2, align='center', alpha  = 0.5, color = 'Green')\n",
    "plt.bar(z, GHS2015_bar.values(), width=0.2, align='center', alpha  = 0.5, color = 'Orange')\n",
    "plt.bar(a, WPE2016_bar.values(), width=0.2, align='center', alpha = 0.5, color = 'Red')\n",
    "\n",
    "bar_leg = ['WorldPop 2015', 'LandScan 2015', 'GHS-Pop 2015', 'ESRI-WPE 2016']\n",
    "plt.legend(bar_leg,loc=2)\n",
    "\n",
    "\n",
    "\n",
    "#plt.bar(range(len(D)), D.values(), align='center')\n",
    "\n",
    "plt.xticks(range(len(WP2015_bar)), WP2015_bar.keys())\n",
    "\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(25, 15)\n",
    "plt.gca().set_yscale('log')\n",
    "plt.xlabel('Population')\n",
    "plt.ylabel('')\n",
    "plt.title('Total Population by Settlement Size for Africa')\n",
    "# fig.savefig('/Users/cascade/Desktop/'+'PopGhana_bar.png', dpi=700, transparent=True)\n",
    "\n",
    "\n",
    "# ax.bar(x-0.2, y,width=0.2,color='b',align='center')\n",
    "# ax.bar(x, z,width=0.2,color='g',align='center')\n",
    "# ax.bar(x+0.2, k,width=0.2,color='r',align='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import plotly.plotly as py\n",
    "# import plotly.tools as tls\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dictionary = plt.figure()\n",
    "\n",
    "bar_leg = ['WorldPop 2015', 'WorldPop 2000']\n",
    "\n",
    "\n",
    "WP2015_Nigeria_bar = {'<50K':WP2015_Nigeria_50k, '50-100K': WP2015_Nigeria_100k, '100-150K':WP2015_Nigeria_250k,\n",
    "    '250-500K' : WP2015_Nigeria_500k, '500K-1m' : WP2015_Nigeria_1m, '1-5M' : WP2015_Nigeria_5m, '>5M' : WP2015_Nigeria_5mplus\n",
    "             }\n",
    "\n",
    "WP2000_Nigeria_bar = {u'Label0':WP2000_Nigeria_50k, u'Label1': WP2000_Nigeria_100k, u'Label2':WP2000_Nigeria_250k,\n",
    "    u'Label3' : WP2000_Nigeria_500k, u'Label4' : WP2000_Nigeria_1m, u'Label5' : WP2000_Nigeria_5m, u'Label6' : WP2000_Nigeria_5mplus\n",
    "    }\n",
    "\n",
    "# make plot\n",
    "sns.set(font_scale=2.2)\n",
    "\n",
    "plt.bar(range(len(WP2000_Nigeria_bar)), WP2000_Nigeria_bar.values(), align='center', alpha  = 0.5, color = 'Purple')\n",
    "plt.bar(range(len(WP2015_Nigeria_bar)), WP2015_Nigeria_bar.values(), align='center', alpha = 0.5, color = 'Orange')\n",
    "plt.legend(bar_leg,loc=2)\n",
    "\n",
    "\n",
    "\n",
    "#plt.bar(range(len(D)), D.values(), align='center')\n",
    "\n",
    "plt.xticks(range(len(WP2015_Nigeria_bar)), WP2015_Nigeria_bar.keys())\n",
    "\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.gca().set_yscale('log')\n",
    "#fig.savefig('/Users/cascade/Desktop/'+'WP152000_Nigeria_bar.png', dpi=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WP 2000 & 2000 Bar Plots Chunk by City Size\n",
    "\n",
    "# drop FID\n",
    "print(len(WP2015))\n",
    "WP2015 = WP2015.drop_duplicates('FID', keep = 'first')\n",
    "print(len(WP2015))\n",
    "\n",
    "# drop <5000\n",
    "WP2015 = WP2015[WP2015['PopTot'] > 5000]\n",
    "print(len(WP2015))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WP2015_aez = WP2015[WP2015['aez_class'] != '0']\n",
    "WP2015_aez = WP2015_aez[WP2015_aez['aez_class'] != 'NoClass']\n",
    "\n",
    "# ax = sns.boxplot(x = 'PopTot', y = 'aez_class', data = WP2000_aez)\n",
    "# ax.set(xscale=\"log\")\n",
    "\n",
    "# fig = matplotlib.pyplot.gcf()\n",
    "# fig.set_size_inches(18.5, 10.55)\n",
    "# plt.xlabel('Population')\n",
    "# plt.ylabel('')\n",
    "# plt.title('WP2000 Distribution by AEZ')\n",
    "\n",
    "# # fig.savefig('test2png.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WP_med2015 = round(WP2015_aez.groupby('aez_class')['PopTot'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  66313.0 - 2000\n",
    "WP_med2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WP_med2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WP2000_aez = WP2000[WP2000['aez_class'] != '0']\n",
    "WP2000_aez = WP2000_aez[WP2000_aez['aez_class'] != 'NoClass']\n",
    "WP2015_aez = WP2015[WP2015['aez_class'] != '0']\n",
    "WP2015_aez = WP2015_aez[WP2015_aez['aez_class'] != 'NoClass']\n",
    "\n",
    "# ax = sns.boxplot(x = 'PopTot', y = 'aez_class', data = WP2000_aez)\n",
    "# ax.set(xscale=\"log\")\n",
    "\n",
    "# fig = matplotlib.pyplot.gcf()\n",
    "# fig.set_size_inches(18.5, 10.55)\n",
    "# plt.xlabel('Population')\n",
    "# plt.ylabel('')\n",
    "# plt.title('WP2000 Distribution by AEZ')\n",
    "\n",
    "#fig.savefig('/Users/cascade/Desktop/'+'WP2000_aez.png', dpi=700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(WP2000_aez.groupby('aez_class')['PopTot'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(WP2015_aez.groupby('aez_class')['PopTot'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*((496037 - 361052)/361052)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add col for concat, drop FID duplicates\n",
    "\n",
    "datasets_string = ['GHS2000', 'GHS2015', 'WP2000', 'WP2015', 'LS2015', 'WPE2016']\n",
    "\n",
    "# for i, dataset in enumerate(datasets_in):\n",
    "    \n",
    "#     dataset['dataset'] = datasets_string[i]\n",
    "#     dataset = dup_drop(dataset, 'FID', 'first')\n",
    "\n",
    "WPE2016['dataset'] = 'WPE2016'\n",
    "WPE2016 = dup_drop(WPE2016, 'FID', 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop cities with less than 5000 \n",
    "GHS2015 = GHS2015[GHS2015['PopTot']>=5000] \n",
    "WP2015 = WP2015[WP2015['PopTot']>=5000] \n",
    "LS2015 = LS2015[LS2015['PopTot']>=5000] \n",
    "WPE2016 = WPE2016[WPE2016['PopTot']>=5000] \n",
    "\n",
    "\n",
    "datasets2015 = [GHS2015, WP2015, LS2015, WPE2016]\n",
    "\n",
    "\n",
    "datasets15_concat = pd.concat(datasets2015, ignore_index=True)\n",
    "\n",
    "# datasets_concat = pd.concat(datasets_in, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets15_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(WPE2016['PopTot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=3)\n",
    "ax = sns.boxplot(x = 'PopTot', y = 'dataset', data = datasets15_concat)\n",
    "ax.set(xscale=\"log\") \n",
    "plt.xlabel('Population')\n",
    "plt.ylabel('')\n",
    "\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "#fig.savefig('/Users/cascade/Desktop/'+'data15-hist.png', dpi=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets2015 = [GHS2015, WP2015, LS2015, WPE2016]\n",
    "\n",
    "\n",
    "GHS2015_sort = GHS2015['PopTot'].sort_values()\n",
    "X0, y0 = p_X_gt_x(GHS2015_sort)\n",
    "\n",
    "WP2015_sort = WP2015['PopTot'].sort_values()\n",
    "X1, y1 = p_X_gt_x(WP2015_sort)\n",
    "\n",
    "LS2015_sort = LS2015['PopTot'].sort_values()\n",
    "X2, y2 = p_X_gt_x(LS2015_sort )\n",
    "\n",
    "WPE2016_sort = WPE2016['PopTot'].sort_values()\n",
    "X3, y3 = p_X_gt_x(WPE2016_sort)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot()\n",
    "ax.plot(X0, y0, label ='GHS2015')\n",
    "ax.plot(X1, y1, label ='WP2015')\n",
    "ax.plot(X2, y2, label ='LS2015')\n",
    "ax.plot(X3, y3, label ='WPE2016')\n",
    "plt.xscale('log')\n",
    "plt.title('Inverse cumulative distribution of city sizes by dataset')\n",
    "plt.xlabel('x(Population)')\n",
    "plt.ylabel('P[X>=x]')\n",
    "ax.legend()\n",
    "fig.set_size_inches(18.5, 10.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GHS2000.loc[(GHS2000['PopTot'] > 5000) & (GHS2000['PopTot'] < 10000), 'PopTot'].sum()\n",
    "test = GHS2015[GHS2015['PopTot'] <5000000]\n",
    "\n",
    "a =test.loc[(test['PopTot'] > 1000000), 'PopTot'].sum()\n",
    "                                         \n",
    "                                          \n",
    "#GHS2000.loc[GHS2000['PopTot'] <50000 & GHS2000['PopTot'] >5000, 'PopTot'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pp\n",
    "val = 0. # this is the value where you want the data to appear on the y-axis.\n",
    " # just as an example array\n",
    "pp.plot(a, 'x')\n",
    "pp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WPE2016.head()\n",
    "\n",
    "a = GHS2015[GHS2015['PopTot']>0]\n",
    "a = GHS2015[GHS2015['PopTot']<1000000]\n",
    "b = GHS2000[GHS2000['PopTot']>0]\n",
    "b = GHS2000[GHS2000['PopTot']<1000000]\n",
    "\n",
    "\n",
    "plt.hist(np.log10(b['PopTot']), alpha=0.5, label='WP2000')\n",
    "plt.hist(np.log10(a['PopTot']), alpha=0.5, label='WP2015')\n",
    "#plt.hist(np.log10(LS2015['PopTot']), alpha=0.5, label='x')\n",
    "#plt.hist(np.log10(a['PopTot']), alpha=0.5, label='x')\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Drop Doubles based on OSM Lat/Lon\n",
    "\n",
    "GHS2000_drop = dup_drop(GHS2000, 'osm_id', 'first')\n",
    "WP2000_drop = dup_drop(WP2000, 'osm_id', 'first')\n",
    "\n",
    "GHS2015_drop = dup_drop(GHS2015, 'osm_id', 'first')\n",
    "WP2015_drop = dup_drop(WP2015 , 'osm_id', 'first')\n",
    "LS2015_drop = dup_drop(LS2015 , 'osm_id', 'first')\n",
    "WPE2016_drop = dup_drop(WPE2016 , 'osm_id', 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GHS2015_pop = GHS2015_drop[['str_id','PopTot']]\n",
    "WP2015_pop = WP2015_drop[['str_id','PopTot']]\n",
    "LS2015_pop = LS2015_drop[['str_id','PopTot']]\n",
    "WPE2016_pop = WPE2016_drop[['str_id','PopTot']]\n",
    "\n",
    "data_frames = [GHS2015_pop, WP2015_pop, LS2015_pop, WPE2016_pop]\n",
    "\n",
    "df2015_merged = reduce(lambda  left,right: pd.merge(left,right,on=['str_id'], how='inner'), data_frames)\n",
    "\n",
    "print(len(df2015_merged))\n",
    "df2015_merged.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2015_merged.columns = ['str_id', 'GHS15_Pop', 'WP15_Pop', 'LS15_Pop', 'WPE2016_pop' ]\n",
    "df2015_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_GHS_WP = df2015_merged[['WPE2016_pop','LS15_Pop']]\n",
    "print(df_2015_GHS_WP.shape)\n",
    "\n",
    "\n",
    "df_2015_GHS_WP = df_2015_GHS_WP.drop_duplicates(keep='first')\n",
    "print(df_2015_GHS_WP.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(df_2015_GHS_WP['WPE2016_pop'], df_2015_GHS_WP['LS15_Pop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015_GHS_WP.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise scatter plots\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.scatter(df_2015_GHS_WP['WPE2016_pop'], df_2015_GHS_WP['LS15_Pop'] , c='blue', alpha=0.05, edgecolors='none')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('ESRI - WPE 2016')\n",
    "plt.ylabel('LandScan 2015')\n",
    "\n",
    "#fig.savefig('/Users/cascade/Desktop/'+'WPE16-LS15.png', dpi=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#axl = pd.scatter_matrix(df2015_merged, alpha = 0.3, figsize = (14,8), diagonal = 'kde')\n",
    "\n",
    "import seaborn as sns\n",
    "corr = df2015_merged.corr()\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#matplotlib.pyplot.scatter(df_merge['PopTot_x'], df_merge['PopTot_y'])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.scatter(test_df_drop['PopTot_x'], test_df_drop['PopTot_y'] , c='blue', alpha=0.05, edgecolors='none')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('WPE 2016')\n",
    "plt.ylabel('World Pop 2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.scatter(test_df_drop['x'], test_df_drop['y'], c='blue', alpha=0.1, edgecolors='none')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('WPE 2016')\n",
    "plt.ylabel('World Pop 2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "xA = df_merge['PopTot_x']\n",
    "yA = df_merge['PopTot_y']\n",
    "\n",
    "result = stats.pearsonr(xA, yA) # return is (Pearson’s correlation coefficient, 2-tailed p-value)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "xR = test_df_drop['x']\n",
    "yR = test_df_drop['y']\n",
    "\n",
    "result = stats.pearsonr(xR, yR) # return is (Pearson’s correlation coefficient, 2-tailed p-value)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_min = test_df_drop[test_df_drop['x']<=1000000]\n",
    "print(len(test_df_min))\n",
    "test_df_min = test_df_drop[test_df_drop['y']<=1000000]\n",
    "print(len(test_df_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_min[test_df_min['y']>=1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xW = test_df_min['x']\n",
    "yW = test_df_min['y']\n",
    "\n",
    "result = stats.pearsonr(xW, yW) # return is (Pearson’s correlation coefficient, 2-tailed p-value)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.scatter(test_df_min['x'], test_df_min['y'], c='blue', alpha=0.1, edgecolors='none')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('WPE 2016')\n",
    "plt.ylabel('World Pop 2015')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_a = WP2015[['osm_id', 'PopTot']]\n",
    "\n",
    "\n",
    "# df_test_b = GHS2015[['osm_id', 'PopTot']]\n",
    "# print(df_test_b.shape)\n",
    "# print(df_test_a.shape)\n",
    "\n",
    "# df_test_a_drop = df_test_a.drop_duplicates('osm_id', keep=False)\n",
    "# df_test_b_drop = df_test_b.drop_duplicates('osm_id', keep=False)\n",
    "# print(df_test_b_drop.shape)\n",
    "# print(df_test_a_drop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find duplicates\n",
    "\n",
    "# dupsA = pd.concat(g for _, g in test_df.groupby(\"str_id\") if len(g) > 1)\n",
    "# dupsA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df_merge['PopTot_x']\n",
    "# y = df_merge['PopTot_y']\n",
    "# str_id_merge = df_merge['str_id']\n",
    "# test_df = pd.DataFrame()\n",
    "# test_df['x'] = x\n",
    "# test_df['y'] = y\n",
    "# test_df['str_id_merge'] = str_id_merge\n",
    "\n",
    "\n",
    "\n",
    "# test_df['x_string'] = test_df.x.astype(str)\n",
    "# test_df['y_string'] = test_df.y.astype(str)\n",
    "# test_df['str_id'] = test_df.x_string.astype(str)+test_df.y_string.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#axl = pd.scatter_matrix(df2015_merged, alpha = 0.3, figsize = (14,8), diagonal = 'kde')\n",
    "\n",
    "# import seaborn as sns\n",
    "# corr = df2015_merged.corr()\n",
    "# sns.heatmap(corr, \n",
    "#             xticklabels=corr.columns.values,\n",
    "#             yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# #matplotlib.pyplot.scatter(df_merge['PopTot_x'], df_merge['PopTot_y'])\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = plt.gca()\n",
    "# ax.scatter(test_df_drop['PopTot_x'], test_df_drop['PopTot_y'] , c='blue', alpha=0.05, edgecolors='none')\n",
    "# ax.set_yscale('log')\n",
    "# ax.set_xscale('log')\n",
    "# plt.xlabel('WPE 2016')\n",
    "# plt.ylabel('World Pop 2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = plt.gca()\n",
    "# ax.scatter(test_df_drop['x'], test_df_drop['y'], c='blue', alpha=0.1, edgecolors='none')\n",
    "# ax.set_yscale('log')\n",
    "# ax.set_xscale('log')\n",
    "# plt.xlabel('WPE 2016')\n",
    "# plt.ylabel('World Pop 2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import stats\n",
    "# xA = df_merge['PopTot_x']\n",
    "# yA = df_merge['PopTot_y']\n",
    "\n",
    "# result = stats.pearsonr(xA, yA) # return is (Pearson’s correlation coefficient, 2-tailed p-value)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import stats\n",
    "# xR = test_df_drop['x']\n",
    "# yR = test_df_drop['y']\n",
    "\n",
    "# result = stats.pearsonr(xR, yR) # return is (Pearson’s correlation coefficient, 2-tailed p-value)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_min = test_df_drop[test_df_drop['x']<=1000000]\n",
    "# print(len(test_df_min))\n",
    "# test_df_min = test_df_drop[test_df_drop['y']<=1000000]\n",
    "# print(len(test_df_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_min[test_df_min['y']>=1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xW = test_df_min['x']\n",
    "# yW = test_df_min['y']\n",
    "\n",
    "# result = stats.pearsonr(xW, yW) # return is (Pearson’s correlation coefficient, 2-tailed p-value)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = plt.gca()\n",
    "# ax.scatter(test_df_min['x'], test_df_min['y'], c='blue', alpha=0.1, edgecolors='none')\n",
    "# ax.set_yscale('log')\n",
    "# ax.set_xscale('log')\n",
    "# plt.xlabel('WPE 2016')\n",
    "# plt.ylabel('World Pop 2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WP 2000 & 2015 Bar Plots Chunk by City Size\n",
    "\n",
    "# # drop FID\n",
    "# print(len(WP2015))\n",
    "# WP2015 = WP2015.drop_duplicates('FID', keep = 'first')\n",
    "# print(len(WP2015))\n",
    "\n",
    "# # drop <5000\n",
    "# WP2015 = WP2015[WP2015['PopTot'] > 5000]\n",
    "# print(len(WP2015))\n",
    "\n",
    "# # WP 2000 & 2015 Bar Plots Chunk by City Size\n",
    "\n",
    "# # drop FID\n",
    "# print(len(WP2015))\n",
    "# LS2015 = LS2015.drop_duplicates('FID', keep = 'first')\n",
    "# print(len(LS2015))\n",
    "\n",
    "# # drop <5000\n",
    "# GHS2015 = GHS2015[GHS2015['PopTot'] > 5000]\n",
    "# print(len(GHS2015))\n",
    "\n",
    "# # WP 2000 & 2015 Bar Plots Chunk by City Size\n",
    "\n",
    "# # drop FID\n",
    "# print(len(WPE2016))\n",
    "# WPE2016 = WPE2016.drop_duplicates('FID', keep = 'first')\n",
    "# print(len(WPE2016))\n",
    "\n",
    "# # drop <5000\n",
    "# WPE2016 = WPE2016[WPE2016['PopTot'] > 5000]\n",
    "# print(len(WPE2016))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop through datasets to drop FID duplicates and remove cities with population less than 5000\n",
    "\n",
    "# for dataset in datasets_in:\n",
    "    \n",
    "#     # drop FID\n",
    "#     print(len(dataset))\n",
    "#     dataset = dataset.drop_duplicates('FID', keep = 'first')\n",
    "#     print(len(dataset))\n",
    "    \n",
    "#     # drop <5000\n",
    "#     dataset = dataset[dataset['PopTot'] > 5000]\n",
    "\n",
    "#     print(len(dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
